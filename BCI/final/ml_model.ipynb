{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authorization classes are not loaded, using fake implementations.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import flet as ft\n",
    "import os\n",
    "import base64\n",
    "from pylsl import StreamInlet, resolve_stream\n",
    "from scipy.signal import welch, spectrogram\n",
    "import pyxdf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def concat_data(frequency):\n",
    "    # โฟลเดอร์ที่เก็บข้อมูล\n",
    "    data_folder = f'../SSVEP_data/{frequency}'\n",
    "\n",
    "    # เก็บข้อมูลจากทุกไฟล์ในโฟลเดอร์\n",
    "    all_data = []\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        streams, _ = pyxdf.load_xdf(file_path)\n",
    "        raw_data = streams[0][\"time_series\"].T\n",
    "        all_data.append(raw_data)\n",
    "\n",
    "    # แปลงเป็น NumPy array และรวมข้อมูลด้วย np.concatenate\n",
    "    all_data_array = np.concatenate(all_data, axis=1)\n",
    "\n",
    "    return all_data_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 159670)\n",
      "(8, 177500)\n",
      "(8, 152760)\n"
     ]
    }
   ],
   "source": [
    "raw_data1 = concat_data('6Hz')\n",
    "print(raw_data1.shape)\n",
    "raw_data2 = concat_data('20Hz')\n",
    "print(raw_data2.shape)\n",
    "raw_data3 = concat_data('0Hz')\n",
    "print(raw_data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streams1, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/6Hz/6hz_1')\n",
    "# raw_data1 = streams1[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "# print(raw_data1.shape)\n",
    "\n",
    "# streams2, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/20Hz/20hz_1')\n",
    "# raw_data2 = streams2[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n",
    "# streams3, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/0Hz/0hz_1')\n",
    "# raw_data3 = streams3[0][\"time_series\"].T #From Steam variable this query is EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = raw_data1[0:4,:]\n",
    "data2 = raw_data2[0:4,:]\n",
    "data3 = raw_data3[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159670\n",
      "177500\n",
      "152760\n"
     ]
    }
   ],
   "source": [
    "data1_oz = data1[0] - data1[1]\n",
    "data1_o1 = data1[2] - data1[1]\n",
    "data1_o2 = data1[3] - data1[1]\n",
    "print(len(data1_o1))\n",
    "data2_oz = data2[0] - data2[1]\n",
    "data2_o1 = data2[2] - data2[1]\n",
    "data2_o2 = data2[3] - data2[1]\n",
    "print(len(data2_o1))\n",
    "data3_oz = data3[0] - data3[1]\n",
    "data3_o1 = data3[2] - data3[1]\n",
    "data3_o2 = data3[3] - data3[1]\n",
    "print(len(data3_o1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlapping_sets(data, set_size=500, overlap_fraction=0.5):\n",
    "    step = int(set_size * (1 - overlap_fraction))\n",
    "    sets = []\n",
    "    for i in range(0, len(data) - set_size + 1, step):\n",
    "        sets.append(data[i:i + set_size])\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_set_oz = create_overlapping_sets(data1_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data1_set_o1 = create_overlapping_sets(data1_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data1_set_o2 = create_overlapping_sets(data1_o2, set_size=1000, overlap_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_set_oz = create_overlapping_sets(data2_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data2_set_o1 = create_overlapping_sets(data2_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data2_set_o2 = create_overlapping_sets(data2_o2, set_size=1000, overlap_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_set_oz = create_overlapping_sets(data3_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data3_set_o1 = create_overlapping_sets(data3_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data3_set_o2 = create_overlapping_sets(data3_o2, set_size=1000, overlap_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "354\n",
      "304\n"
     ]
    }
   ],
   "source": [
    "print(len(data1_set_oz))\n",
    "print(len(data2_set_oz))\n",
    "print(len(data3_set_oz))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, Pxx = welch(data_oz, fs=250, nperseg= 250*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_fft_oz = []\n",
    "data1_fft_o1 = []\n",
    "data1_fft_o2 = []\n",
    "for i in range(len(data1_set_oz)):\n",
    "    f, Pxx = welch(data1_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data1_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data1_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data1_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data1_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data1_fft_o2.append(Pxx[0:121])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.25  0.5   0.75  1.    1.25  1.5   1.75  2.    2.25  2.5   2.75\n",
      "  3.    3.25  3.5   3.75  4.    4.25  4.5   4.75  5.    5.25  5.5   5.75\n",
      "  6.    6.25  6.5   6.75  7.    7.25  7.5   7.75  8.    8.25  8.5   8.75\n",
      "  9.    9.25  9.5   9.75 10.   10.25 10.5  10.75 11.   11.25 11.5  11.75\n",
      " 12.   12.25 12.5  12.75 13.   13.25 13.5  13.75 14.   14.25 14.5  14.75\n",
      " 15.   15.25 15.5  15.75 16.   16.25 16.5  16.75 17.   17.25 17.5  17.75\n",
      " 18.   18.25 18.5  18.75 19.   19.25 19.5  19.75 20.   20.25 20.5  20.75\n",
      " 21.   21.25 21.5  21.75 22.   22.25 22.5  22.75 23.   23.25 23.5  23.75\n",
      " 24.   24.25 24.5  24.75 25.   25.25 25.5  25.75 26.   26.25 26.5  26.75\n",
      " 27.   27.25 27.5  27.75 28.   28.25 28.5  28.75 29.   29.25 29.5  29.75\n",
      " 30.  ]\n"
     ]
    }
   ],
   "source": [
    "print(f[0:121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_fft_oz = []\n",
    "data2_fft_o1 = []\n",
    "data2_fft_o2 = []\n",
    "for i in range(len(data2_set_oz)):\n",
    "    f, Pxx = welch(data2_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data2_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data2_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data2_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data2_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data2_fft_o2.append(Pxx[0:121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_fft_oz = []\n",
    "data3_fft_o1 = []\n",
    "data3_fft_o2 = []\n",
    "for i in range(len(data3_set_oz)):\n",
    "    f, Pxx = welch(data3_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data3_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data3_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data3_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data3_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data3_fft_o2.append(Pxx[0:121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3_fft_oz = np.array(data3_fft_oz)\n",
    "# data3_fft_o1 = np.array(data3_fft_o1)\n",
    "# data3_fft_o2 = np.array(data3_fft_o2)\n",
    "# print(data3_fft_o2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "(976, 363)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap\n",
    "# รวมข้อมูลจากทุก feature สำหรับแต่ละ class และ flatten ข้อมูล\n",
    "combined_data1 = np.hstack((data1_fft_oz, data1_fft_o1, data1_fft_o2))\n",
    "combined_data2 = np.hstack((data2_fft_oz, data2_fft_o1, data2_fft_o2))\n",
    "combined_data3 = np.hstack((data3_fft_oz, data3_fft_o1, data3_fft_o2))\n",
    "\n",
    "# รวมข้อมูลจากทุก class เข้าด้วยกัน\n",
    "combined_data = np.vstack((combined_data1, combined_data2, combined_data3))\n",
    "\n",
    "# ตรวจสอบว่าข้อมูลมีขนาดที่ถูกต้อง\n",
    "print(combined_data.shape)  # ควรได้ (จำนวน samples ทั้งหมด, จำนวน features)\n",
    "\n",
    "# สร้าง label สำหรับแต่ละ class\n",
    "labels = np.array([0]*len(data1_fft_oz) + [1]*len(data2_fft_oz) + [2]*len(data3_fft_oz))\n",
    "\n",
    "# ทำ UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors = 50)\n",
    "embedding = reducer.fit_transform(combined_data)\n",
    "\n",
    "# แสดงผลการลดมิติ\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='Spectral', s=5)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title('UMAP projection of the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(976, 363)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   1.000000  0.983607  0.991736  1.000000\n",
      "1          1.0   0.987179  1.000000  0.993548  0.987179\n",
      "2          2.0   1.000000  1.000000  1.000000  1.000000\n",
      "average    NaN   0.994963  0.994898  0.994893  0.994898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/random_forest_model.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึกโมเดล Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "precision_lda_per_class = precision_score(y_test, y_pred_rf, average=None)\n",
    "recall_lda_per_class = recall_score(y_test, y_pred_rf, average=None)\n",
    "f1_lda_per_class = f1_score(y_test, y_pred_rf, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lda_per_class = []\n",
    "for class_label in range(len(precision_lda_per_class)):\n",
    "    correct_predictions = ((y_pred_rf == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_rf == class_label).sum()\n",
    "    # print(y_pred_rf)\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lda_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lda = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lda = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "avg_recall_lda = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "avg_f1_lda = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lda_per_class)),\n",
    "    'Precision': precision_lda_per_class,\n",
    "    'Recall': recall_lda_per_class,\n",
    "    'F1-score': f1_lda_per_class,\n",
    "    'Accuracy': accuracy_lda_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_df.loc['average'] = [None, avg_precision_lda, avg_recall_lda, avg_f1_lda, avg_accuracy_lda]\n",
    "\n",
    "print(results_df)\n",
    "dump(rf_classifier, 'model/random_forest_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.800000  0.852459  0.825397  0.800000\n",
      "1          1.0   0.863014  0.818182  0.840000  0.863014\n",
      "2          2.0   0.982759  0.982759  0.982759  0.982759\n",
      "average    NaN   0.878837  0.877551  0.877700  0.877551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/svm_model.joblib']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึกโมเดล SVM 'poly' 'linear' 'rbf'\n",
    "svm_classifier = SVC(C=0.1, gamma=1, kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_lda_per_class = precision_score(y_test, y_pred_svm, average=None)\n",
    "recall_lda_per_class = recall_score(y_test, y_pred_svm, average=None)\n",
    "f1_lda_per_class = f1_score(y_test, y_pred_svm, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lda_per_class = []\n",
    "for class_label in range(len(precision_lda_per_class)):\n",
    "    correct_predictions = ((y_pred_svm == class_label) & (y_test == class_label)).sum()\n",
    "    # print(y_test)\n",
    "    total_predictions = (y_pred_svm == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lda_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lda = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lda = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "avg_recall_lda = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "avg_f1_lda = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lda_per_class)),\n",
    "    'Precision': precision_lda_per_class,\n",
    "    'Recall': recall_lda_per_class,\n",
    "    'F1-score': f1_lda_per_class,\n",
    "    'Accuracy': accuracy_lda_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_df.loc['average'] = [None, avg_precision_lda, avg_recall_lda, avg_f1_lda, avg_accuracy_lda]\n",
    "\n",
    "print(results_df)\n",
    "dump(svm_classifier, 'model/svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # แบ่งข้อมูลเป็น train set และ test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # กำหนดช่วงของ hyperparameters ที่ต้องการทดสอบ\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],  # regularization parameter\n",
    "#     'gamma': [1, 0.1, 0.01, 0.001],  # kernel coefficient\n",
    "#     'kernel': ['rbf', 'linear', 'poly']  # kernel function\n",
    "# }\n",
    "\n",
    "# # สร้าง GridSearchCV object\n",
    "# grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# # ฝึกโมเดล\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # แสดง hyperparameters ที่ดีที่สุด\n",
    "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# # ทำนายบน test set\n",
    "# y_pred_svm = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# # ประเมินประสิทธิภาพของโมเดล SVM ที่ปรับ hyperparameters แล้ว\n",
    "# accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "# print(\"SVM Accuracy:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   1.000000  0.967213  0.983333  1.000000\n",
      "1          1.0   0.986301  0.935065  0.960000  0.986301\n",
      "2          2.0   0.906250  1.000000  0.950820  0.906250\n",
      "average    NaN   0.966876  0.964286  0.964545  0.964286\n",
      "SVM Confusion Matrix:\n",
      "[[59  1  1]\n",
      " [ 0 72  5]\n",
      " [ 0  0 58]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/lda_model.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึกโมเดล LDA\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_lda = lda_classifier.predict(X_test)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_lda_per_class = precision_score(y_test, y_pred_lda, average=None)\n",
    "recall_lda_per_class = recall_score(y_test, y_pred_lda, average=None)\n",
    "f1_lda_per_class = f1_score(y_test, y_pred_lda, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lda_per_class = []\n",
    "for class_label in range(len(precision_lda_per_class)):\n",
    "    correct_predictions = ((y_pred_lda == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_lda == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lda_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lda = precision_score(y_test, y_pred_lda, average='weighted')\n",
    "avg_recall_lda = recall_score(y_test, y_pred_lda, average='weighted')\n",
    "avg_f1_lda = f1_score(y_test, y_pred_lda, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lda_per_class)),\n",
    "    'Precision': precision_lda_per_class,\n",
    "    'Recall': recall_lda_per_class,\n",
    "    'F1-score': f1_lda_per_class,\n",
    "    'Accuracy': accuracy_lda_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_df.loc['average'] = [None, avg_precision_lda, avg_recall_lda, avg_f1_lda, avg_accuracy_lda]\n",
    "\n",
    "print(results_df)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_lda)\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(conf_matrix_svm)\n",
    "dump(lda_classifier, 'model/lda_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.784615  0.836066  0.809524  0.784615\n",
      "1          1.0   0.828571  0.753247  0.789116  0.828571\n",
      "2          2.0   0.868852  0.913793  0.890756  0.868852\n",
      "average    NaN   0.826811  0.826531  0.825545  0.826531\n",
      "KNN Confusion Matrix:\n",
      "[[51  8  2]\n",
      " [13 58  6]\n",
      " [ 1  4 53]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/knn_model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# สร้างและฝึกโมเดล KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_knn_per_class = precision_score(y_test, y_pred_knn, average=None)\n",
    "recall_knn_per_class = recall_score(y_test, y_pred_knn, average=None)\n",
    "f1_knn_per_class = f1_score(y_test, y_pred_knn, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_knn_per_class = []\n",
    "for class_label in range(len(precision_knn_per_class)):\n",
    "    correct_predictions = ((y_pred_knn == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_knn == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_knn_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_knn = precision_score(y_test, y_pred_knn, average='weighted')\n",
    "avg_recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "avg_f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_knn_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_knn_per_class)),\n",
    "    'Precision': precision_knn_per_class,\n",
    "    'Recall': recall_knn_per_class,\n",
    "    'F1-score': f1_knn_per_class,\n",
    "    'Accuracy': accuracy_knn_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_knn_df.loc['average'] = [None, avg_precision_knn, avg_recall_knn, avg_f1_knn, avg_accuracy_knn]\n",
    "\n",
    "print(results_knn_df)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "print(conf_matrix_knn)\n",
    "dump(knn_classifier, 'model/knn_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "25/25 [==============================] - 1s 3ms/step - loss: 375693472.0000 - accuracy: 0.5077\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 5436003.5000 - accuracy: 0.6987\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7622.1025 - accuracy: 0.7654\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5359.8931 - accuracy: 0.7987\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1099.7253 - accuracy: 0.8192\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2100.5713 - accuracy: 0.8077\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 117.0654 - accuracy: 0.8167\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 459.3702 - accuracy: 0.8244\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 436.6971 - accuracy: 0.8423\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 100.7159 - accuracy: 0.8321\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 94.4786 - accuracy: 0.8564\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 70.1445 - accuracy: 0.8705\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 51.0414 - accuracy: 0.8667\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 29.0070 - accuracy: 0.8949\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 39.7945 - accuracy: 0.8692\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 21.5751 - accuracy: 0.9000\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 17.7155 - accuracy: 0.9179\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 54.5589 - accuracy: 0.9179\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1368.0461 - accuracy: 0.9064\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 564.6048 - accuracy: 0.9103\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 34.4504 - accuracy: 0.9154\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 35.2341 - accuracy: 0.9333\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 38.7679 - accuracy: 0.9090\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 51.3393 - accuracy: 0.8731\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 36.9561 - accuracy: 0.9077\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 17.0374 - accuracy: 0.9449\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 20.9796 - accuracy: 0.9256\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 25.6594 - accuracy: 0.9051\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 20.4584 - accuracy: 0.9231\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.0444 - accuracy: 0.9718\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 12.7199 - accuracy: 0.9538\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 15.6571 - accuracy: 0.9538\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.1225 - accuracy: 0.9564\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 7.0088 - accuracy: 0.9795\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.5114 - accuracy: 0.9679\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.3299 - accuracy: 0.9667\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 6.9470 - accuracy: 0.9487\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 11.3975 - accuracy: 0.9333\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.9202 - accuracy: 0.9577\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.8641 - accuracy: 0.9564\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0158 - accuracy: 0.9654\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 2.4672 - accuracy: 0.9808\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.9203 - accuracy: 0.9744\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.2173 - accuracy: 0.9590\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.4933 - accuracy: 0.9782\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.5325 - accuracy: 0.9538\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 5.0511 - accuracy: 0.9641\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 1.9438 - accuracy: 0.9718\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.7983 - accuracy: 0.9577\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.9949\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.796875  0.836066  0.816000  0.796875\n",
      "1          1.0   0.884058  0.792208  0.835616  0.884058\n",
      "2          2.0   0.904762  0.982759  0.942149  0.904762\n",
      "average    NaN   0.863051  0.862245  0.861036  0.862245\n",
      "ANN Confusion Matrix:\n",
      "[[51  7  3]\n",
      " [13 61  3]\n",
      " [ 0  1 57]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# แปลง y_train และ y_test ให้เป็นแบบ one-hot encoding\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# สร้างโมเดล ANN แบบ Feed-Forward\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "ann_model.add(Dense(64, activation='relu'))\n",
    "ann_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# ฝึกโมเดล\n",
    "ann_model.fit(X_train, y_train_one_hot, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_ann = np.argmax(ann_model.predict(X_test), axis=1)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_ann_per_class = precision_score(y_test, y_pred_ann, average=None)\n",
    "recall_ann_per_class = recall_score(y_test, y_pred_ann, average=None)\n",
    "f1_ann_per_class = f1_score(y_test, y_pred_ann, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_ann_per_class = []\n",
    "for class_label in range(len(precision_ann_per_class)):\n",
    "    correct_predictions = ((y_pred_ann == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_ann == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_ann_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_ann = accuracy_score(y_test, y_pred_ann)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_ann = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "avg_recall_ann = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "avg_f1_ann = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_ann_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_ann_per_class)),\n",
    "    'Precision': precision_ann_per_class,\n",
    "    'Recall': recall_ann_per_class,\n",
    "    'F1-score': f1_ann_per_class,\n",
    "    'Accuracy': accuracy_ann_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_ann_df.loc['average'] = [None, avg_precision_ann, avg_recall_ann, avg_f1_ann, avg_accuracy_ann]\n",
    "\n",
    "print(results_ann_df)\n",
    "conf_matrix_ann = confusion_matrix(y_test, y_pred_ann)\n",
    "print(\"ANN Confusion Matrix:\")\n",
    "print(conf_matrix_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 2s 23ms/step - loss: 0.5083 - accuracy: 0.8641\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.3401 - accuracy: 0.9205\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.3010 - accuracy: 0.9628\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 1s 25ms/step - loss: 0.2666 - accuracy: 0.9692\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.1510 - accuracy: 0.9667\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.1648 - accuracy: 0.9654\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.2972 - accuracy: 0.9692\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1221 - accuracy: 0.9795\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1112 - accuracy: 0.9782\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1631 - accuracy: 0.9795\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.1256 - accuracy: 0.9769\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.1830 - accuracy: 0.9705\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0996 - accuracy: 0.9795\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0704 - accuracy: 0.9872\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0712 - accuracy: 0.9910\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0698 - accuracy: 0.9872\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0611 - accuracy: 0.9846\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0650 - accuracy: 0.9897\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0684 - accuracy: 0.9859\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0600 - accuracy: 0.9885\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1099 - accuracy: 0.9833\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1291 - accuracy: 0.9808\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.2187 - accuracy: 0.9833\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0909 - accuracy: 0.9821\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1651 - accuracy: 0.9769\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0618 - accuracy: 0.9846\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1182 - accuracy: 0.9756\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0930 - accuracy: 0.9859\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.1184 - accuracy: 0.9731\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0572 - accuracy: 0.9897\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0438 - accuracy: 0.9885\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0402 - accuracy: 0.9910\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0451 - accuracy: 0.9897\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0516 - accuracy: 0.9846\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0330 - accuracy: 0.9923\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0416 - accuracy: 0.9885\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0344 - accuracy: 0.9910\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0372 - accuracy: 0.9910\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0348 - accuracy: 0.9936\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0348 - accuracy: 0.9897\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0353 - accuracy: 0.9910\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0330 - accuracy: 0.9872\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0310 - accuracy: 0.9936\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0234 - accuracy: 0.9949\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0192 - accuracy: 0.9962\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0175 - accuracy: 0.9974\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0259 - accuracy: 0.9910\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0238 - accuracy: 0.9936\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0166 - accuracy: 0.9962\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0157 - accuracy: 0.9949\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0150 - accuracy: 0.9962\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0173 - accuracy: 0.9974\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0138 - accuracy: 0.9974\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0165 - accuracy: 0.9949\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0104 - accuracy: 0.9962\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0238 - accuracy: 0.9910\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0194 - accuracy: 0.9962\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0176 - accuracy: 0.9949\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0171 - accuracy: 0.9949\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0149 - accuracy: 0.9974\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0127 - accuracy: 0.9974\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0126 - accuracy: 0.9936\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0117 - accuracy: 0.9949\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0065 - accuracy: 0.9987\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0119 - accuracy: 0.9962\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0114 - accuracy: 0.9962\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 1s 26ms/step - loss: 0.0121 - accuracy: 0.9962\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0096 - accuracy: 0.9987\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0117 - accuracy: 0.9962\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0090 - accuracy: 0.9974\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0133 - accuracy: 0.9949\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0170 - accuracy: 0.9949\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0050 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0218 - accuracy: 0.9936\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0284 - accuracy: 0.9949\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0130 - accuracy: 0.9962\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0096 - accuracy: 0.9962\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0066 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0146 - accuracy: 0.9962\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0070 - accuracy: 0.9987\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0113 - accuracy: 0.9962\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0058 - accuracy: 0.9987\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0064 - accuracy: 0.9987\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0031 - accuracy: 0.9987\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0044 - accuracy: 0.9987\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0072 - accuracy: 0.9987\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0056 - accuracy: 0.9987\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 1s 24ms/step - loss: 0.0078 - accuracy: 0.9974\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 1s 23ms/step - loss: 0.0077 - accuracy: 0.9974\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 1s 22ms/step - loss: 0.0085 - accuracy: 0.9962\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 1s 21ms/step - loss: 0.0079 - accuracy: 0.9974\n",
      "7/7 [==============================] - 0s 4ms/step\n",
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   1.000000  0.950820  0.974790  1.000000\n",
      "1          1.0   1.000000  1.000000  1.000000  1.000000\n",
      "2          2.0   0.950820  1.000000  0.974790  0.950820\n",
      "average    NaN   0.985447  0.984694  0.984694  0.984694\n",
      "CNN Confusion Matrix:\n",
      "[[58  0  3]\n",
      " [ 0 77  0]\n",
      " [ 0  0 58]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dense, ReLU, Softmax, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize ข้อมูล\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ปรับข้อมูลให้เป็นรูปแบบ 3D สำหรับ Conv1D\n",
    "X_train_reshaped = X_train.reshape(-1, 363, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 363, 1)\n",
    "\n",
    "# สร้างโมเดล CNN สำหรับข้อมูล 1D\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution Layer\n",
    "model.add(Conv1D(filters=64, kernel_size=3, input_shape=(363, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(ReLU())\n",
    "\n",
    "# เพิ่มอีก Convolution Layer\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(ReLU())\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256))\n",
    "model.add(ReLU())\n",
    "\n",
    "# Output Layer\n",
    "num_classes = len(np.unique(y_train))\n",
    "model.add(Dense(units=num_classes))\n",
    "model.add(Softmax())\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# แปลง y_train และ y_test ให้เป็นแบบ one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# ฝึกโมเดล\n",
    "model.fit(X_train_reshaped, y_train_one_hot, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_cnn = np.argmax(model.predict(X_test_reshaped), axis=1)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_cnn_per_class = precision_score(y_test, y_pred_cnn, average=None)\n",
    "recall_cnn_per_class = recall_score(y_test, y_pred_cnn, average=None)\n",
    "f1_cnn_per_class = f1_score(y_test, y_pred_cnn, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_cnn_per_class = []\n",
    "for class_label in range(len(precision_cnn_per_class)):\n",
    "    correct_predictions = ((y_pred_cnn == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_cnn == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_cnn_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_cnn = precision_score(y_test, y_pred_cnn, average='weighted')\n",
    "avg_recall_cnn = recall_score(y_test, y_pred_cnn, average='weighted')\n",
    "avg_f1_cnn = f1_score(y_test, y_pred_cnn, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_cnn_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_cnn_per_class)),\n",
    "    'Precision': precision_cnn_per_class,\n",
    "    'Recall': recall_cnn_per_class,\n",
    "    'F1-score': f1_cnn_per_class,\n",
    "    'Accuracy': accuracy_cnn_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_cnn_df.loc['average'] = [None, avg_precision_cnn, avg_recall_cnn, avg_f1_cnn, avg_accuracy_cnn]\n",
    "\n",
    "print(results_cnn_df)\n",
    "conf_matrix_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
    "print(\"CNN Confusion Matrix:\")\n",
    "print(conf_matrix_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "25/25 [==============================] - 9s 216ms/step - loss: 1.1057 - accuracy: 0.3333 - val_loss: 1.1010 - val_accuracy: 0.3827 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.1032 - accuracy: 0.3564 - val_loss: 1.0991 - val_accuracy: 0.3163 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "25/25 [==============================] - 4s 181ms/step - loss: 1.1017 - accuracy: 0.3462 - val_loss: 1.0955 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.1018 - accuracy: 0.3551 - val_loss: 1.0936 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.1004 - accuracy: 0.3551 - val_loss: 1.0943 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 1.0996 - accuracy: 0.3551 - val_loss: 1.0920 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0989 - accuracy: 0.3551 - val_loss: 1.0913 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0982 - accuracy: 0.3551 - val_loss: 1.0907 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0981 - accuracy: 0.3551 - val_loss: 1.0899 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 1.0980 - accuracy: 0.3551 - val_loss: 1.0884 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0974 - accuracy: 0.3551 - val_loss: 1.0847 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0914 - accuracy: 0.3551 - val_loss: 1.0527 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.1153 - accuracy: 0.3449 - val_loss: 1.0932 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.1014 - accuracy: 0.3500 - val_loss: 1.0901 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0977 - accuracy: 0.3551 - val_loss: 1.0887 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 1.0974 - accuracy: 0.3551 - val_loss: 1.0869 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0972 - accuracy: 0.3551 - val_loss: 1.0855 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0968 - accuracy: 0.3551 - val_loss: 1.0853 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0972 - accuracy: 0.3551 - val_loss: 1.0844 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0966 - accuracy: 0.3551 - val_loss: 1.0844 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0966 - accuracy: 0.3551 - val_loss: 1.0836 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.0963 - accuracy: 0.3551\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0963 - accuracy: 0.3551 - val_loss: 1.0831 - val_accuracy: 0.3929 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0831 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0831 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0829 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0829 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0828 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0828 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0962 - accuracy: 0.3551 - val_loss: 1.0828 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0828 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0962 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.3551\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 34/200\n",
      "25/25 [==============================] - 5s 182ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 1.0962 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "25/25 [==============================] - 4s 179ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0827 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.0960 - accuracy: 0.3551\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0962 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0826 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0825 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 87/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 88/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 89/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 90/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 91/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 92/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0824 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 93/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 94/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 95/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 96/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 97/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 98/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 99/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 100/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 101/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 102/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 103/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 104/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 105/200\n",
      "25/25 [==============================] - 4s 179ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 106/200\n",
      "25/25 [==============================] - 5s 206ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0823 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 107/200\n",
      "25/25 [==============================] - 5s 181ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 108/200\n",
      "25/25 [==============================] - 5s 196ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 109/200\n",
      "25/25 [==============================] - 5s 192ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 110/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 111/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 112/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 113/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 114/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 115/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 116/200\n",
      "25/25 [==============================] - 4s 178ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 117/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 118/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 119/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0822 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 120/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 121/200\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 122/200\n",
      "25/25 [==============================] - 5s 182ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 123/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 124/200\n",
      "25/25 [==============================] - 4s 179ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 125/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 126/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 127/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 128/200\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 129/200\n",
      "25/25 [==============================] - 4s 175ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 130/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 131/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 132/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 133/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0821 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 134/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 135/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 136/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 137/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 138/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 139/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0961 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 140/200\n",
      "25/25 [==============================] - 4s 174ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 141/200\n",
      "25/25 [==============================] - 5s 183ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 142/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 143/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 144/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0955 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 145/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 146/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0820 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 147/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 148/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 149/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 150/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 151/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 152/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0956 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 153/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 154/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 155/200\n",
      "25/25 [==============================] - 4s 169ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 156/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 157/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 158/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0819 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 159/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 160/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 161/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 162/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 163/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 164/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 165/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 166/200\n",
      "25/25 [==============================] - 4s 165ms/step - loss: 1.0956 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 167/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 168/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 169/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 170/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 171/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 172/200\n",
      "25/25 [==============================] - 4s 164ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0818 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 173/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 174/200\n",
      "25/25 [==============================] - 4s 160ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 175/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0955 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 176/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 177/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 178/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 179/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 180/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 181/200\n",
      "25/25 [==============================] - 4s 162ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0817 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 182/200\n",
      "25/25 [==============================] - 4s 163ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 183/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 184/200\n",
      "25/25 [==============================] - 4s 161ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 185/200\n",
      "25/25 [==============================] - 4s 167ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 186/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0956 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 187/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 188/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0955 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 189/200\n",
      "25/25 [==============================] - 5s 189ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 190/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 191/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 192/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 193/200\n",
      "25/25 [==============================] - 4s 171ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0816 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 194/200\n",
      "25/25 [==============================] - 4s 177ms/step - loss: 1.0957 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 195/200\n",
      "25/25 [==============================] - 4s 170ms/step - loss: 1.0956 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 196/200\n",
      "25/25 [==============================] - 4s 176ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 197/200\n",
      "25/25 [==============================] - 4s 168ms/step - loss: 1.0956 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 198/200\n",
      "25/25 [==============================] - 4s 172ms/step - loss: 1.0960 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 199/200\n",
      "25/25 [==============================] - 4s 173ms/step - loss: 1.0958 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "Epoch 200/200\n",
      "25/25 [==============================] - 4s 166ms/step - loss: 1.0959 - accuracy: 0.3551 - val_loss: 1.0815 - val_accuracy: 0.3929 - lr: 1.0000e-05\n",
      "7/7 [==============================] - 1s 56ms/step\n",
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.000000  0.000000  0.000000  0.000000\n",
      "1          1.0   0.392857  1.000000  0.564103  0.392857\n",
      "2          2.0   0.000000  0.000000  0.000000  0.000000\n",
      "average    NaN   0.154337  0.392857  0.221612  0.392857\n",
      "LSTM Confusion Matrix:\n",
      "[[ 0 61  0]\n",
      " [ 0 77  0]\n",
      " [ 0 58  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize ข้อมูล\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ปรับข้อมูลให้เป็นรูปแบบ 3D สำหรับ LSTM\n",
    "X_train_reshaped = X_train.reshape(-1, 363, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 363, 1)\n",
    "\n",
    "# สร้างโมเดล LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM Layer 1\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(363, 1), kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# LSTM Layer 2\n",
    "model.add(LSTM(70, return_sequences=False, kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(5, activation='relu'))\n",
    "\n",
    "# Output Layer with Softmax\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# แปลง y_train และ y_test ให้เป็นแบบ one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=len(np.unique(y_train)))\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(np.unique(y_train)))\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "# ฝึกโมเดล\n",
    "model.fit(X_train_reshaped, y_train_one_hot, epochs=200, batch_size=32, validation_data=(X_test_reshaped, y_test_one_hot), callbacks=[reduce_lr], verbose=1)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_lstm = np.argmax(model.predict(X_test_reshaped), axis=1)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_lstm_per_class = precision_score(y_test, y_pred_lstm, average=None)\n",
    "recall_lstm_per_class = recall_score(y_test, y_pred_lstm, average=None)\n",
    "f1_lstm_per_class = f1_score(y_test, y_pred_lstm, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lstm_per_class = []\n",
    "for class_label in range(len(precision_lstm_per_class)):\n",
    "    correct_predictions = ((y_pred_lstm == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_lstm == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lstm_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lstm = precision_score(y_test, y_pred_lstm, average='weighted')\n",
    "avg_recall_lstm = recall_score(y_test, y_pred_lstm, average='weighted')\n",
    "avg_f1_lstm = f1_score(y_test, y_pred_lstm, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_lstm_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lstm_per_class)),\n",
    "    'Precision': precision_lstm_per_class,\n",
    "    'Recall': recall_lstm_per_class,\n",
    "    'F1-score': f1_lstm_per_class,\n",
    "    'Accuracy': accuracy_lstm_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_lstm_df.loc['average'] = [None, avg_precision_lstm, avg_recall_lstm, avg_f1_lstm, avg_accuracy_lstm]\n",
    "\n",
    "print(results_lstm_df)\n",
    "conf_matrix_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
    "print(\"LSTM Confusion Matrix:\")\n",
    "print(conf_matrix_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_test1, header = pyxdf.load_xdf('../flicker/6Hz/6Hz_4')\n",
    "raw_test1 = streams_test1[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n",
    "streams_test2, header = pyxdf.load_xdf('../flicker/20Hz_10')\n",
    "raw_test2 = streams_test2[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n",
    "streams_test3, header = pyxdf.load_xdf('../SSVEP_data/0Hz/0hz_10')\n",
    "raw_test3 = streams_test3[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 363)\n",
      "(57,)\n"
     ]
    }
   ],
   "source": [
    "data_test1 = raw_test1[0:4,:]\n",
    "data_test1_oz = data_test1[0] - data_test1[1]\n",
    "data_test1_o1 = data_test1[2] - data_test1[1]\n",
    "data_test1_o2 = data_test1[3] - data_test1[1]\n",
    "data_test1_set_oz = create_overlapping_sets(data_test1_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data_test1_set_o1 = create_overlapping_sets(data_test1_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data_test1_set_o2 = create_overlapping_sets(data_test1_o2, set_size=1000, overlap_fraction=0.5)\n",
    "data_test1_fft_oz = []\n",
    "data_test1_fft_o2 = []\n",
    "data_test1_fft_o1 = []\n",
    "for i in range(len(data_test1_set_oz)):\n",
    "    f, Pxx = welch(data_test1_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data_test1_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test1_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data_test1_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test1_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data_test1_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "combined_test1 = np.hstack((data_test1_fft_oz, data_test1_fft_o1, data_test1_fft_o2))\n",
    "# labels_test1 = np.array([0]*len(data_test1_fft_oz))\n",
    "# print(combined_test1.shape)\n",
    "# print(labels_test1.shape)\n",
    "data_test2 = raw_test2[0:4,:]\n",
    "data_test2_oz = data_test2[0] - data_test2[1]\n",
    "data_test2_o1 = data_test2[2] - data_test2[1]\n",
    "data_test2_o2 = data_test2[3] - data_test2[1]\n",
    "data_test2_set_oz = create_overlapping_sets(data_test2_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data_test2_set_o1 = create_overlapping_sets(data_test2_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data_test2_set_o2 = create_overlapping_sets(data_test2_o2, set_size=1000, overlap_fraction=0.5)\n",
    "data_test2_fft_oz = []\n",
    "data_test2_fft_o2 = []\n",
    "data_test2_fft_o1 = []\n",
    "for i in range(len(data_test2_set_oz)):\n",
    "    f, Pxx = welch(data_test2_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data_test2_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test2_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data_test2_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test2_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data_test2_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "combined_test2 = np.hstack((data_test2_fft_oz, data_test2_fft_o1, data_test2_fft_o2))\n",
    "# labels_test2 = np.array([0]*len(data_test2_fft_oz))\n",
    "# print(combined_test2.shape)\n",
    "# print(labels_test2.shape)\n",
    "\n",
    "data_test3 = raw_test3[0:4,:]\n",
    "data_test3_oz = data_test3[0] - data_test3[1]\n",
    "data_test3_o1 = data_test3[2] - data_test3[1]\n",
    "data_test3_o2 = data_test3[3] - data_test3[1]\n",
    "data_test3_set_oz = create_overlapping_sets(data_test3_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data_test3_set_o1 = create_overlapping_sets(data_test3_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data_test3_set_o2 = create_overlapping_sets(data_test3_o2, set_size=1000, overlap_fraction=0.5)\n",
    "data_test3_fft_oz = []\n",
    "data_test3_fft_o2 = []\n",
    "data_test3_fft_o1 = []\n",
    "for i in range(len(data_test3_set_oz)):\n",
    "    f, Pxx = welch(data_test3_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data_test3_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test3_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data_test3_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test3_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data_test3_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "combined_test3 = np.hstack((data_test3_fft_oz, data_test3_fft_o1, data_test3_fft_o2))\n",
    "# labels_test3 = np.array([0]*len(data_test3_fft_oz))\n",
    "# print(combined_test3.shape)\n",
    "# print(labels_test3.shape)\n",
    "\n",
    "# รวมข้อมูลจากทุก class เข้าด้วยกัน\n",
    "combined_test = np.vstack((combined_test1, combined_test2, combined_test3))\n",
    "\n",
    "  # ควรได้ (จำนวน samples ทั้งหมด, จำนวน features)\n",
    "\n",
    "# สร้าง label สำหรับแต่ละ class\n",
    "labels_test = np.array([0]*len(data_test1_fft_oz) + [1]*len(data_test2_fft_oz) + [2]*len(data_test3_fft_oz))\n",
    "# ตรวจสอบว่าข้อมูลมีขนาดที่ถูกต้อง\n",
    "print(combined_test.shape)\n",
    "print(labels_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_test = rf_classifier.predict(combined_test)\n",
    "y_pred_svm_test = svm_classifier.predict(combined_test)\n",
    "y_pred_lda_test = lda_classifier.predict(combined_test)\n",
    "y_pred_knn_test = knn_classifier.predict(combined_test)\n",
    "\n",
    "avg_accuracy_rf_test = accuracy_score(y_pred_rf_test, labels_test)\n",
    "avg_accuracy_svm_test = accuracy_score(y_pred_svm_test, labels_test)\n",
    "avg_accuracy_lda_test = accuracy_score(y_pred_lda_test, labels_test)\n",
    "avg_accuracy_knn_test = accuracy_score(y_pred_knn_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Precision_RF  Recall_RF     F1_RF  Precision_SVM  Recall_SVM    F1_SVM  \\\n",
      "Class                                                                           \n",
      "0          0.230769   0.214286  0.222222            0.5         1.0  0.666667   \n",
      "1          0.285714   0.285714  0.285714            0.0         0.0  0.000000   \n",
      "2          0.966667   1.000000  0.983051            1.0         1.0  1.000000   \n",
      "\n",
      "       Precision_LDA  Recall_LDA    F1_LDA  Precision_KNN  Recall_KNN  \\\n",
      "Class                                                                   \n",
      "0           0.642857    0.642857  0.642857       0.000000    0.000000   \n",
      "1           0.571429    0.285714  0.380952       0.466667    1.000000   \n",
      "2           0.805556    1.000000  0.892308       1.000000    0.931034   \n",
      "\n",
      "         F1_KNN  \n",
      "Class            \n",
      "0      0.000000  \n",
      "1      0.636364  \n",
      "2      0.964286  \n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      " [[ 3 10  1]\n",
      " [10  4  0]\n",
      " [ 0  0 29]]\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      " [[14  0  0]\n",
      " [14  0  0]\n",
      " [ 0  0 29]]\n",
      "\n",
      "Confusion Matrix for LDA:\n",
      " [[ 9  3  2]\n",
      " [ 5  4  5]\n",
      " [ 0  0 29]]\n",
      "\n",
      "Confusion Matrix for KNN:\n",
      " [[ 0 14  0]\n",
      " [ 0 14  0]\n",
      " [ 0  2 27]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming y_pred_rf_test, y_pred_svm_test, y_pred_lda_test, y_pred_knn_test, and labels_test are already defined\n",
    "\n",
    "def compute_metrics(y_true, y_pred, classes):\n",
    "    precision = precision_score(y_true, y_pred, average=None, labels=classes)\n",
    "    recall = recall_score(y_true, y_pred, average=None, labels=classes)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, labels=classes)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    return precision, recall, f1, conf_matrix\n",
    "\n",
    "classes = np.unique(labels_test)\n",
    "\n",
    "# Calculate metrics for each classifier\n",
    "precision_rf, recall_rf, f1_rf, conf_matrix_rf = compute_metrics(labels_test, y_pred_rf_test, classes)\n",
    "precision_svm, recall_svm, f1_svm, conf_matrix_svm = compute_metrics(labels_test, y_pred_svm_test, classes)\n",
    "precision_lda, recall_lda, f1_lda, conf_matrix_lda = compute_metrics(labels_test, y_pred_lda_test, classes)\n",
    "precision_knn, recall_knn, f1_knn, conf_matrix_knn = compute_metrics(labels_test, y_pred_knn_test, classes)\n",
    "\n",
    "# Create DataFrames to display the results\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': classes,\n",
    "    'Precision_RF': precision_rf,\n",
    "    'Recall_RF': recall_rf,\n",
    "    'F1_RF': f1_rf,\n",
    "    'Precision_SVM': precision_svm,\n",
    "    'Recall_SVM': recall_svm,\n",
    "    'F1_SVM': f1_svm,\n",
    "    'Precision_LDA': precision_lda,\n",
    "    'Recall_LDA': recall_lda,\n",
    "    'F1_LDA': f1_lda,\n",
    "    'Precision_KNN': precision_knn,\n",
    "    'Recall_KNN': recall_knn,\n",
    "    'F1_KNN': f1_knn\n",
    "})\n",
    "\n",
    "metrics_df.set_index('Class', inplace=True)\n",
    "\n",
    "# Display the confusion matrices separately\n",
    "confusion_matrices = {\n",
    "    'Random Forest': conf_matrix_rf,\n",
    "    'SVM': conf_matrix_svm,\n",
    "    'LDA': conf_matrix_lda,\n",
    "    'KNN': conf_matrix_knn\n",
    "}\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "# Print confusion matrices\n",
    "for clf_name, conf_matrix in confusion_matrices.items():\n",
    "    print(f\"\\nConfusion Matrix for {clf_name}:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
