{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pylsl import StreamInlet, resolve_stream\n",
    "# import numpy as np\n",
    "# from time import sleep\n",
    "# import threading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import threading\n",
    "# from time import sleep\n",
    "# from pylsl import resolve_stream, StreamInlet\n",
    "# import numpy as np\n",
    "# from queue import Queue\n",
    "\n",
    "# class EEGReceiver:\n",
    "#     def __init__(self):\n",
    "#         self.data_queue = Queue()\n",
    "#         self.running = True\n",
    "\n",
    "#     def receive_eeg_data(self):\n",
    "#         target_samples = 1000  # จำนวนตัวอย่างที่ต้องการสะสมก่อนประมวลผล\n",
    "#         num_samples_per_iteration = 250  # จำนวนตัวอย่างที่รับต่อการวนลูปแต่ละครั้ง\n",
    "#         target_stream_name = 'obci_eeg1'\n",
    "        \n",
    "#         print(\"กำลังค้นหาสตรีม...\")\n",
    "#         All_streams = resolve_stream()\n",
    "#         EEG_streams = [stream for stream in All_streams if stream.name() == target_stream_name]\n",
    "        \n",
    "#         if len(EEG_streams) == 0:\n",
    "#             print(\"Error: ไม่พบสตรีม EEG\")\n",
    "#             return\n",
    "        \n",
    "#         print(f\"พบสตรีม EEG '{target_stream_name}' แล้ว.\")\n",
    "#         inlet = StreamInlet(EEG_streams[0])\n",
    "        \n",
    "#         total_samples_collected = 0  # ตัวแปรเพื่อเก็บจำนวนตัวอย่างที่รับมาแล้ว\n",
    "#         samples_buffer = []  # บัฟเฟอร์เพื่อสะสมตัวอย่าง\n",
    "\n",
    "#         while self.running:\n",
    "#             samples = []\n",
    "#             for i in range(num_samples_per_iteration):\n",
    "#                 sample, timestamp = inlet.pull_sample()\n",
    "#                 if sample is not None:\n",
    "#                     samples.append(sample)\n",
    "            \n",
    "#             if samples:\n",
    "#                 samples_buffer.append(np.array(samples).T)\n",
    "#                 total_samples_collected += len(samples)\n",
    "#                 print(f\"ได้รับ {len(samples)} ตัวอย่าง, ขนาดบัฟเฟอร์: {total_samples_collected}\")\n",
    "            \n",
    "#             # เช็คว่ามีตัวอย่างครบ 1000 หรือไม่\n",
    "#             if total_samples_collected >= target_samples:\n",
    "#                 all_samples = np.hstack(samples_buffer)\n",
    "#                 self.data_queue.put(all_samples)  # ส่งข้อมูลไปที่คิว\n",
    "#                 print(\"สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\")\n",
    "#                 total_samples_collected = 0  # รีเซ็ตตัวแปรเพื่อสะสมตัวอย่างใหม่\n",
    "#                 samples_buffer = []  # เคลียร์บัฟเฟอร์\n",
    "            \n",
    "#             # sleep(0.1)  # ลดเวลา sleep เพื่อให้สามารถรับข้อมูลได้รวดเร็วยิ่งขึ้น\n",
    "\n",
    "#     def process_data(self):\n",
    "#         while self.running or not self.data_queue.empty():\n",
    "#             if not self.data_queue.empty():\n",
    "#                 data = self.data_queue.get()\n",
    "#                 # ประมวลผลข้อมูลที่นี่\n",
    "#                 print(f\"กำลังประมวลผลข้อมูลขนาด: {data.shape}\")\n",
    "#             else:\n",
    "#                 sleep(0.1)\n",
    "\n",
    "# # สร้างอินสแตนซ์ของ EEGReceiver\n",
    "# receiver = EEGReceiver()\n",
    "\n",
    "# # เริ่มเธรดการรับข้อมูล\n",
    "# eeg_thread = threading.Thread(target=receiver.receive_eeg_data, daemon=True)\n",
    "# eeg_thread.start()\n",
    "\n",
    "# # เริ่มเธรดการประมวลผลข้อมูล\n",
    "# processing_thread = threading.Thread(target=receiver.process_data, daemon=True)\n",
    "# processing_thread.start()\n",
    "\n",
    "# # เพื่อหยุดเธรดในภายหลัง คุณสามารถตั้งค่า receiver.running เป็น False\n",
    "# # receiver.running = False\n",
    "# # eeg_thread.join()\n",
    "# # processing_thread.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กำลังค้นหาสตรีม...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "พบสตรีม EEG 'obci_eeg1' แล้ว.\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n",
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 250\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 250\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 500\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 500\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n",
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 250\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 500\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n",
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 250\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 500\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n",
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 250\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 500\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n",
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 250\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 500\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 750\n",
      "ได้รับ 250 ตัวอย่าง, ขนาดบัฟเฟอร์: 1000\n",
      "สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\n",
      "กำลังประมวลผลข้อมูลขนาด: (8, 1000)\n"
     ]
    }
   ],
   "source": [
    "# import threading\n",
    "# from time import sleep\n",
    "# from pylsl import resolve_stream, StreamInlet\n",
    "# import numpy as np\n",
    "# from queue import Queue\n",
    "# from scipy.signal import welch, spectrogram\n",
    "\n",
    "# class EEGReceiver:\n",
    "#     def __init__(self):\n",
    "#         self.data_queue = Queue()\n",
    "#         self.running = False\n",
    "#         self.ready_for_processing = False\n",
    "\n",
    "#     def receive_eeg_data(self):\n",
    "#         target_samples = 1000  # จำนวนตัวอย่างที่ต้องการสะสมก่อนประมวลผล\n",
    "#         num_samples_per_iteration = 250  # จำนวนตัวอย่างที่รับต่อการวนลูปแต่ละครั้ง\n",
    "#         target_stream_name = 'obci_eeg1'\n",
    "        \n",
    "#         print(\"กำลังค้นหาสตรีม...\")\n",
    "#         All_streams = resolve_stream()\n",
    "#         EEG_streams = [stream for stream in All_streams if stream.name() == target_stream_name]\n",
    "        \n",
    "#         if len(EEG_streams) == 0:\n",
    "#             print(\"Error: ไม่พบสตรีม EEG\")\n",
    "#             return\n",
    "        \n",
    "#         print(f\"พบสตรีม EEG '{target_stream_name}' แล้ว.\")\n",
    "#         inlet = StreamInlet(EEG_streams[0])\n",
    "        \n",
    "#         total_samples_collected = 0  # ตัวแปรเพื่อเก็บจำนวนตัวอย่างที่รับมาแล้ว\n",
    "#         samples_buffer = []  # บัฟเฟอร์เพื่อสะสมตัวอย่าง\n",
    "\n",
    "#         while self.running:\n",
    "#             samples = []\n",
    "#             for i in range(num_samples_per_iteration):\n",
    "#                 sample, timestamp = inlet.pull_sample()\n",
    "#                 if sample is not None:\n",
    "#                     samples.append(sample)\n",
    "            \n",
    "#             if samples:\n",
    "#                 samples_buffer.append(np.array(samples).T)\n",
    "#                 total_samples_collected += len(samples)\n",
    "#                 print(f\"ได้รับ {len(samples)} ตัวอย่าง, ขนาดบัฟเฟอร์: {total_samples_collected}\")\n",
    "            \n",
    "#             # เช็คว่ามีตัวอย่างครบ 1000 หรือไม่\n",
    "#             if total_samples_collected >= target_samples:\n",
    "#                 all_samples = np.hstack(samples_buffer)\n",
    "#                 self.data_queue.put(all_samples)  # ส่งข้อมูลไปที่คิว\n",
    "#                 print(\"สะสมครบ 1000 ตัวอย่างแล้ว ส่งข้อมูลไปที่คิว\")\n",
    "#                 total_samples_collected = 0  # รีเซ็ตตัวแปรเพื่อสะสมตัวอย่างใหม่\n",
    "#                 samples_buffer = []  # เคลียร์บัฟเฟอร์\n",
    "#                 self.ready_for_processing = True  # ตั้งสถานะเป็นพร้อมที่จะนำข้อมูลไปประมวลผล\n",
    "#                 sleep(0.1)  # รอเพื่อให้โปรแกรมหลักส่งสัญญาณให้เริ่มการสะสมข้อมูลใหม่\n",
    "#             else:\n",
    "#                 sleep(0.1)  # รอสักครู่ก่อนที่จะวนลูปการรับข้อมูลใหม่\n",
    "\n",
    "#     def process_data(self):\n",
    "#         while True:\n",
    "#             if self.ready_for_processing and not self.data_queue.empty():\n",
    "#                 data = self.data_queue.get()\n",
    "#                 # ประมวลผลข้อมูลที่นี่\n",
    "#                 print(f\"กำลังประมวลผลข้อมูลขนาด: {data.shape}\")\n",
    "#                 self.ready_for_processing = False  # ตั้งสถานะเป็นไม่พร้อมสำหรับการประมวลผลใหม่\n",
    "#             else:\n",
    "#                 sleep(0.1)\n",
    "\n",
    "# # สร้างอินสแตนซ์ของ EEGReceiver\n",
    "# receiver = EEGReceiver()\n",
    "\n",
    "# # เริ่มเธรดการรับข้อมูล\n",
    "# eeg_thread = threading.Thread(target=receiver.receive_eeg_data, daemon=True)\n",
    "# eeg_thread.start()\n",
    "\n",
    "# # เริ่มเธรดการประมวลผลข้อมูล\n",
    "# processing_thread = threading.Thread(target=receiver.process_data, daemon=True)\n",
    "# processing_thread.start()\n",
    "\n",
    "# # ลูปหลักสำหรับทดสอบ\n",
    "# for i in range(10):\n",
    "#     # สั่งให้เธรดการรับข้อมูลเริ่มสะสมข้อมูล\n",
    "#     print(i)\n",
    "# receiver.running = True\n",
    "    \n",
    "#     # รอเพื่อให้ข้อมูลสะสมครบ 1000 ตัวอย่าง\n",
    "# while not receiver.ready_for_processing:\n",
    "#     sleep(1)\n",
    "    \n",
    "#     # สั่งให้เธรดการรับข้อมูลหยุดสะสมข้อมูลและส่งข้อมูลไปที่คิวเพื่อประมวลผล\n",
    "# receiver.running = False\n",
    "\n",
    "# # เพื่อหยุดเธรดในภายหลัง คุณสามารถตั้งค่า receiver.running เป็น False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for streams...\n",
      "EEG stream 'obci_eeg1' found.\n",
      "Get 250 samples, buffer size: 250\n",
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "1000 samples have been accumulated. Send the data to the queue.\n",
      "pre_rf => [2]\n",
      "pre_svm => [0]\n",
      "pre_lda => [1]\n",
      "pre_knn => [1]\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "from time import sleep\n",
    "from pylsl import resolve_stream, StreamInlet\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from scipy.signal import welch, spectrogram\n",
    "from joblib import load\n",
    "\n",
    "class EEGReceiver:\n",
    "    def __init__(self):\n",
    "        self.data_queue = Queue()\n",
    "        self.running = False\n",
    "        self.ready_for_processing = False\n",
    "\n",
    "    def receive_eeg_data(self):\n",
    "        target_samples = 1000  \n",
    "        num_samples_per_iteration = 250  \n",
    "        target_stream_name = 'obci_eeg1'\n",
    "        \n",
    "        print(\"Searching for streams...\")\n",
    "        All_streams = resolve_stream()\n",
    "        EEG_streams = [stream for stream in All_streams if stream.name() == target_stream_name]\n",
    "        \n",
    "        if len(EEG_streams) == 0:\n",
    "            print(\"Error: No EEG stream found.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"EEG stream '{target_stream_name}' found.\")\n",
    "        inlet = StreamInlet(EEG_streams[0])\n",
    "        \n",
    "        total_samples_collected = 0  \n",
    "        samples_buffer = [] \n",
    "        while not self.running:\n",
    "            sample, timestamp = inlet.pull_sample()\n",
    "            # print(sample)\n",
    "\n",
    "        while self.running:\n",
    "            samples = []\n",
    "            for i in range(num_samples_per_iteration):\n",
    "                sample, timestamp = inlet.pull_sample()\n",
    "                if sample is not None:\n",
    "                    samples.append(sample)\n",
    "            \n",
    "            if samples:\n",
    "                samples_buffer.append(np.array(samples).T)\n",
    "                total_samples_collected += len(samples)\n",
    "                print(f\"Get {len(samples)} samples, buffer size: {total_samples_collected}\")\n",
    "     \n",
    "            if total_samples_collected >= target_samples:\n",
    "                all_samples = np.hstack(samples_buffer)\n",
    "                self.data_queue.put(all_samples) \n",
    "                print(\"1000 samples have been accumulated. Send the data to the queue.\")\n",
    "                total_samples_collected = 0 \n",
    "                samples_buffer = []  \n",
    "                self.ready_for_processing = True \n",
    "                self.running = False\n",
    "                sleep(0.1)  \n",
    "            else:\n",
    "                sleep(0.1)  \n",
    "\n",
    "    def process_data(self):\n",
    "        rf_model = load('model/random_forest_model.joblib')\n",
    "        svm_model = load('model/svm_model.joblib')\n",
    "        lda_model = load('model/lda_model.joblib')\n",
    "        knn_model = load('model/knn_model.joblib')\n",
    "        while True:\n",
    "            if self.ready_for_processing and not self.data_queue.empty():\n",
    "                data = self.data_queue.get()\n",
    "                data = data[0:4,:]\n",
    "                data_oz = data[0] - data[1]\n",
    "                data_o1 = data[2] - data[1]\n",
    "                data_o2 = data[3] - data[1]\n",
    "                data_fft_oz = []\n",
    "                data_fft_o2 = []\n",
    "                data_fft_o1 = []\n",
    "                \n",
    "        \n",
    "                f, Pxx = welch(data_oz, fs=250, nperseg= 250*4)\n",
    "                data_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "                f, Pxx = welch(data_o1, fs=250, nperseg= 250*4)\n",
    "                data_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "                f, Pxx = welch(data_o2, fs=250, nperseg= 250*4)\n",
    "                data_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "                combined = np.hstack((data_fft_oz, data_fft_o1, data_fft_o2))\n",
    "                # print(f\"Processing data size: {combined.shape}\")\n",
    "                pre_rf = rf_model.predict(combined)\n",
    "                pre_svm = svm_model.predict(combined)\n",
    "                pre_lda = lda_model.predict(combined)\n",
    "                pre_knn = knn_model.predict(combined)\n",
    "\n",
    "                print(f'pre_rf => {pre_rf}')\n",
    "                print(f'pre_svm => {pre_svm}')\n",
    "                print(f'pre_lda => {pre_lda}')\n",
    "                print(f'pre_knn => {pre_knn}')\n",
    "                \n",
    "                \n",
    "                self.ready_for_processing = False  \n",
    "            else:\n",
    "                sleep(0.1)\n",
    "\n",
    "receiver = EEGReceiver()\n",
    "\n",
    "eeg_thread = threading.Thread(target=receiver.receive_eeg_data, daemon=True)\n",
    "eeg_thread.start()\n",
    "\n",
    "processing_thread = threading.Thread(target=receiver.process_data, daemon=True)\n",
    "processing_thread.start()\n",
    "\n",
    "receiver.running = True\n",
    "sleep(20)\n",
    "receiver.running = True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 250 samples, buffer size: 250\n",
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "1000 samples have been accumulated. Send the data to the queue.\n",
      "pre_rf => [2]\n",
      "pre_svm => [0]\n",
      "pre_lda => [1]\n",
      "pre_knn => [1]\n"
     ]
    }
   ],
   "source": [
    "receiver.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "receiver.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for streams...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG stream 'obci_eeg1' found.\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time \n",
    "from pylsl import resolve_stream, StreamInlet\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "from scipy.signal import welch\n",
    "from joblib import load\n",
    "\n",
    "class EEGReceiver:\n",
    "    def __init__(self):\n",
    "        self.data_queue = Queue()\n",
    "        self.running = False\n",
    "        self.ready_for_processing = False\n",
    "        self.start_time = None  # เพิ่มตัวแปรเพื่อเก็บเวลาเริ่มต้น\n",
    "\n",
    "    def receive_eeg_data(self):\n",
    "        target_duration = 4  # 4 วินาที\n",
    "        num_samples_per_iteration = 250  \n",
    "        target_stream_name = 'obci_eeg1'\n",
    "        \n",
    "        print(\"Searching for streams...\")\n",
    "        All_streams = resolve_stream()\n",
    "        EEG_streams = [stream for stream in All_streams if stream.name() == target_stream_name]\n",
    "        \n",
    "        if len(EEG_streams) == 0:\n",
    "            print(\"Error: No EEG stream found.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"EEG stream '{target_stream_name}' found.\")\n",
    "        inlet = StreamInlet(EEG_streams[0])\n",
    "        \n",
    "        total_samples_collected = 0  \n",
    "        samples_buffer = [] \n",
    "        state = 0\n",
    "        while True:\n",
    "            if state == 0 and self.running and len(samples_buffer) == 0 and total_samples_collected == 0:\n",
    "                print('Begin')\n",
    "                state = 1\n",
    "            elif self.running and state == 1:\n",
    "                if self.start_time is None:\n",
    "                    self.start_time = time.time()  # เก็บเวลาเริ่มต้น\n",
    "                \n",
    "                samples = []\n",
    "                for i in range(num_samples_per_iteration):\n",
    "                    sample, timestamp = inlet.pull_sample()\n",
    "                    if sample is not None:\n",
    "                        samples.append(sample)\n",
    "                \n",
    "                if samples:\n",
    "                    samples_buffer.append(np.array(samples).T)\n",
    "                    total_samples_collected += len(samples)\n",
    "                    # print(f\"Get {len(samples)} samples, buffer size: {total_samples_collected}\")\n",
    "         \n",
    "                current_time = time.time()\n",
    "                if current_time - self.start_time >= target_duration:\n",
    "                    all_samples = np.hstack(samples_buffer)\n",
    "                    self.data_queue.put(all_samples) \n",
    "                    print(\"4 seconds have passed Send information to the queue\")\n",
    "                    total_samples_collected = 0 \n",
    "                    samples_buffer = []  \n",
    "                    self.ready_for_processing = True \n",
    "                    state = 0\n",
    "                    self.running = False\n",
    "                    self.start_time = None  # reset เวลาเริ่มต้น\n",
    "                 \n",
    "\n",
    "    def process_data(self):\n",
    "        rf_model = load('model/random_forest_model.joblib')\n",
    "        svm_model = load('model/svm_model.joblib')\n",
    "        lda_model = load('model/lda_model.joblib')\n",
    "        knn_model = load('model/knn_model.joblib')\n",
    "        while True:\n",
    "            if self.ready_for_processing and not self.data_queue.empty():\n",
    "                data = self.data_queue.get()\n",
    "                data = data[0:4,:]\n",
    "                data_oz = data[0] - data[1]\n",
    "                data_o1 = data[2] - data[1]\n",
    "                data_o2 = data[3] - data[1]\n",
    "                data_fft_oz = []\n",
    "                data_fft_o2 = []\n",
    "                data_fft_o1 = []\n",
    "                \n",
    "        \n",
    "                f, Pxx = welch(data_oz, fs=250, nperseg= 250*4)\n",
    "                data_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "                f, Pxx = welch(data_o1, fs=250, nperseg= 250*4)\n",
    "                data_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "                f, Pxx = welch(data_o2, fs=250, nperseg= 250*4)\n",
    "                data_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "                combined = np.hstack((data_fft_oz, data_fft_o1, data_fft_o2))\n",
    "                # print(f\"Processing data size: {combined.shape}\")\n",
    "                pre_rf = rf_model.predict(combined)\n",
    "                pre_svm = svm_model.predict(combined)\n",
    "                pre_lda = lda_model.predict(combined)\n",
    "                pre_knn = knn_model.predict(combined)\n",
    "\n",
    "                print(f'pre_rf => {pre_rf}')\n",
    "                print(f'pre_svm => {pre_svm}')\n",
    "                print(f'pre_lda => {pre_lda}')\n",
    "                print(f'pre_knn => {pre_knn}')\n",
    "                \n",
    "                \n",
    "                self.ready_for_processing = False  \n",
    "        \n",
    "receiver = EEGReceiver()\n",
    "\n",
    "eeg_thread = threading.Thread(target=receiver.receive_eeg_data, daemon=True)\n",
    "eeg_thread.start()\n",
    "\n",
    "processing_thread = threading.Thread(target=receiver.process_data, daemon=True)\n",
    "processing_thread.start()\n",
    "\n",
    "# เริ่มการเก็บข้อมูลเมื่อค่า running เป็น True\n",
    "# receiver.running = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 250 samples, buffer size: 250\n",
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "4 วินาทีผ่านไปแล้ว ส่งข้อมูลไปยังคิว\n",
      "pre_rf => [1]\n",
      "pre_svm => [1]\n",
      "pre_lda => [1]\n",
      "pre_knn => [1]\n"
     ]
    }
   ],
   "source": [
    "receiver.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "Get 250 samples, buffer size: 250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "Get 250 samples, buffer size: 1250\n",
      "Get 250 samples, buffer size: 1500\n",
      "Get 250 samples, buffer size: 1750\n",
      "Get 250 samples, buffer size: 2000\n",
      "4 วินาทีผ่านไปแล้ว ส่งข้อมูลไปยังคิว\n",
      "pre_rf => [1]\n",
      "pre_svm => [0]\n",
      "pre_lda => [0]\n",
      "pre_knn => [1]\n"
     ]
    }
   ],
   "source": [
    "receiver.running = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 250 samples, buffer size: 250\n",
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "Get 250 samples, buffer size: 1250\n",
      "Get 250 samples, buffer size: 1500\n",
      "4 วินาทีผ่านไปแล้ว ส่งข้อมูลไปยังคิว\n",
      "pre_rf => [1]\n",
      "pre_svm => [0]\n",
      "pre_lda => [0]\n",
      "pre_knn => [1]\n"
     ]
    }
   ],
   "source": [
    "receiver.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 250 samples, buffer size: 250\n",
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "Get 250 samples, buffer size: 1250\n",
      "Get 250 samples, buffer size: 1500\n",
      "Get 250 samples, buffer size: 1750\n",
      "Get 250 samples, buffer size: 2000\n",
      "4 วินาทีผ่านไปแล้ว ส่งข้อมูลไปยังคิว\n",
      "pre_rf => [1]\n",
      "pre_svm => [0]\n",
      "pre_lda => [1]\n",
      "pre_knn => [1]\n"
     ]
    }
   ],
   "source": [
    "receiver.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin\n",
      "Get 250 samples, buffer size: 250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get 250 samples, buffer size: 500\n",
      "Get 250 samples, buffer size: 750\n",
      "Get 250 samples, buffer size: 1000\n",
      "Get 250 samples, buffer size: 1250\n",
      "Get 250 samples, buffer size: 1500\n",
      "Get 250 samples, buffer size: 1750\n",
      "4 วินาทีผ่านไปแล้ว ส่งข้อมูลไปยังคิว\n",
      "pre_rf => [1]\n",
      "pre_svm => [1]\n",
      "pre_lda => [2]\n",
      "pre_knn => [2]\n"
     ]
    }
   ],
   "source": [
    "receiver.running = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
