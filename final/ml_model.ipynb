{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import flet as ft\n",
    "import os\n",
    "import base64\n",
    "from pylsl import StreamInlet, resolve_stream\n",
    "from scipy.signal import welch, spectrogram\n",
    "import pyxdf\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import pandas as pd\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxdf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def concat_data(frequency):\n",
    "    # โฟลเดอร์ที่เก็บข้อมูล\n",
    "    data_folder = f'../../../data_ssvep/Toey/SSVEP_data/{frequency}/'\n",
    "\n",
    "    # เก็บข้อมูลจากทุกไฟล์ในโฟลเดอร์\n",
    "    all_data = []\n",
    "    for file_name in os.listdir(data_folder):\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        streams, _ = pyxdf.load_xdf(file_path)\n",
    "        raw_data = streams[0][\"time_series\"].T\n",
    "        all_data.append(raw_data)\n",
    "\n",
    "    # แปลงเป็น NumPy array และรวมข้อมูลด้วย np.concatenate\n",
    "    all_data_array = np.concatenate(all_data, axis=1)\n",
    "\n",
    "    return all_data_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 144520)\n",
      "(8, 164360)\n",
      "(8, 137610)\n"
     ]
    }
   ],
   "source": [
    "raw_data1 = concat_data('6Hz')\n",
    "print(raw_data1.shape)\n",
    "raw_data2 = concat_data('20Hz')\n",
    "print(raw_data2.shape)\n",
    "raw_data3 = concat_data('0Hz')\n",
    "print(raw_data3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streams1, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/6Hz/6hz_1')\n",
    "# raw_data1 = streams1[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "# print(raw_data1.shape)\n",
    "\n",
    "# streams2, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/20Hz/20hz_1')\n",
    "# raw_data2 = streams2[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n",
    "# streams3, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/0Hz/0hz_1')\n",
    "# raw_data3 = streams3[0][\"time_series\"].T #From Steam variable this query is EEG data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = raw_data1[0:4,:]\n",
    "data2 = raw_data2[0:4,:]\n",
    "data3 = raw_data3[0:4,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144520\n",
      "164360\n",
      "137610\n"
     ]
    }
   ],
   "source": [
    "data1_oz = data1[0] - data1[1]\n",
    "data1_o1 = data1[2] - data1[1]\n",
    "data1_o2 = data1[3] - data1[1]\n",
    "print(len(data1_o1))\n",
    "data2_oz = data2[0] - data2[1]\n",
    "data2_o1 = data2[2] - data2[1]\n",
    "data2_o2 = data2[3] - data2[1]\n",
    "print(len(data2_o1))\n",
    "data3_oz = data3[0] - data3[1]\n",
    "data3_o1 = data3[2] - data3[1]\n",
    "data3_o2 = data3[3] - data3[1]\n",
    "print(len(data3_o1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_overlapping_sets(data, set_size=500, overlap_fraction=0.5):\n",
    "    step = int(set_size * (1 - overlap_fraction))\n",
    "    sets = []\n",
    "    for i in range(0, len(data) - set_size + 1, step):\n",
    "        sets.append(data[i:i + set_size])\n",
    "    return sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_set_oz = create_overlapping_sets(data1_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data1_set_o1 = create_overlapping_sets(data1_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data1_set_o2 = create_overlapping_sets(data1_o2, set_size=1000, overlap_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_set_oz = create_overlapping_sets(data2_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data2_set_o1 = create_overlapping_sets(data2_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data2_set_o2 = create_overlapping_sets(data2_o2, set_size=1000, overlap_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_set_oz = create_overlapping_sets(data3_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data3_set_o1 = create_overlapping_sets(data3_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data3_set_o2 = create_overlapping_sets(data3_o2, set_size=1000, overlap_fraction=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "327\n",
      "274\n"
     ]
    }
   ],
   "source": [
    "print(len(data1_set_oz))\n",
    "print(len(data2_set_oz))\n",
    "print(len(data3_set_oz))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, Pxx = welch(data_oz, fs=250, nperseg= 250*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_fft_oz = []\n",
    "data1_fft_o1 = []\n",
    "data1_fft_o2 = []\n",
    "for i in range(len(data1_set_oz)):\n",
    "    f, Pxx = welch(data1_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data1_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data1_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data1_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data1_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data1_fft_o2.append(Pxx[0:121])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.25  0.5   0.75  1.    1.25  1.5   1.75  2.    2.25  2.5   2.75\n",
      "  3.    3.25  3.5   3.75  4.    4.25  4.5   4.75  5.    5.25  5.5   5.75\n",
      "  6.    6.25  6.5   6.75  7.    7.25  7.5   7.75  8.    8.25  8.5   8.75\n",
      "  9.    9.25  9.5   9.75 10.   10.25 10.5  10.75 11.   11.25 11.5  11.75\n",
      " 12.   12.25 12.5  12.75 13.   13.25 13.5  13.75 14.   14.25 14.5  14.75\n",
      " 15.   15.25 15.5  15.75 16.   16.25 16.5  16.75 17.   17.25 17.5  17.75\n",
      " 18.   18.25 18.5  18.75 19.   19.25 19.5  19.75 20.   20.25 20.5  20.75\n",
      " 21.   21.25 21.5  21.75 22.   22.25 22.5  22.75 23.   23.25 23.5  23.75\n",
      " 24.   24.25 24.5  24.75 25.   25.25 25.5  25.75 26.   26.25 26.5  26.75\n",
      " 27.   27.25 27.5  27.75 28.   28.25 28.5  28.75 29.   29.25 29.5  29.75\n",
      " 30.  ]\n"
     ]
    }
   ],
   "source": [
    "print(f[0:121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_fft_oz = []\n",
    "data2_fft_o1 = []\n",
    "data2_fft_o2 = []\n",
    "for i in range(len(data2_set_oz)):\n",
    "    f, Pxx = welch(data2_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data2_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data2_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data2_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data2_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data2_fft_o2.append(Pxx[0:121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_fft_oz = []\n",
    "data3_fft_o1 = []\n",
    "data3_fft_o2 = []\n",
    "for i in range(len(data3_set_oz)):\n",
    "    f, Pxx = welch(data3_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data3_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data3_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data3_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data3_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data3_fft_o2.append(Pxx[0:121])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data3_fft_oz = np.array(data3_fft_oz)\n",
    "# data3_fft_o1 = np.array(data3_fft_o1)\n",
    "# data3_fft_o2 = np.array(data3_fft_o2)\n",
    "# print(data3_fft_o2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 363)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\umap\\umap_.py:1945: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(f\"n_jobs value {self.n_jobs} overridden to 1 by setting random_state. Use no seed for parallelism.\")\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import umap\n",
    "# รวมข้อมูลจากทุก feature สำหรับแต่ละ class และ flatten ข้อมูล\n",
    "combined_data1 = np.hstack((data1_fft_oz, data1_fft_o1, data1_fft_o2))\n",
    "combined_data2 = np.hstack((data2_fft_oz, data2_fft_o1, data2_fft_o2))\n",
    "combined_data3 = np.hstack((data3_fft_oz, data3_fft_o1, data3_fft_o2))\n",
    "\n",
    "# รวมข้อมูลจากทุก class เข้าด้วยกัน\n",
    "combined_data = np.vstack((combined_data1, combined_data2, combined_data3))\n",
    "\n",
    "# ตรวจสอบว่าข้อมูลมีขนาดที่ถูกต้อง\n",
    "print(combined_data.shape)  # ควรได้ (จำนวน samples ทั้งหมด, จำนวน features)\n",
    "\n",
    "# สร้าง label สำหรับแต่ละ class\n",
    "labels = np.array([0]*len(data1_fft_oz) + [1]*len(data2_fft_oz) + [2]*len(data3_fft_oz))\n",
    "\n",
    "# ทำ UMAP\n",
    "reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors = 50)\n",
    "embedding = reducer.fit_transform(combined_data)\n",
    "\n",
    "# แสดงผลการลดมิติ\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1], c=labels, cmap='Spectral', s=5)\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title('UMAP projection of the dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 363)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "print(combined_data.shape)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.981481  0.946429  0.963636  0.981481\n",
      "1          1.0   0.985294  0.957143  0.971014  0.985294\n",
      "2          2.0   0.928571  1.000000  0.962963  0.928571\n",
      "average    NaN   0.967524  0.966292  0.966341  0.966292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/random_forest_model.joblib']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึกโมเดล Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "precision_lda_per_class = precision_score(y_test, y_pred_rf, average=None)\n",
    "recall_lda_per_class = recall_score(y_test, y_pred_rf, average=None)\n",
    "f1_lda_per_class = f1_score(y_test, y_pred_rf, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lda_per_class = []\n",
    "for class_label in range(len(precision_lda_per_class)):\n",
    "    correct_predictions = ((y_pred_rf == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_rf == class_label).sum()\n",
    "    # print(y_pred_rf)\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lda_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lda = accuracy_score(y_test, y_pred_rf)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lda = precision_score(y_test, y_pred_rf, average='weighted')\n",
    "avg_recall_lda = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "avg_f1_lda = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lda_per_class)),\n",
    "    'Precision': precision_lda_per_class,\n",
    "    'Recall': recall_lda_per_class,\n",
    "    'F1-score': f1_lda_per_class,\n",
    "    'Accuracy': accuracy_lda_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_df.loc['average'] = [None, avg_precision_lda, avg_recall_lda, avg_f1_lda, avg_accuracy_lda]\n",
    "\n",
    "print(results_df)\n",
    "dump(rf_classifier, 'model/random_forest_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.774194  0.857143  0.813559  0.774194\n",
      "1          1.0   0.876923  0.814286  0.844444  0.876923\n",
      "2          2.0   1.000000  0.980769  0.990291  1.000000\n",
      "average    NaN   0.880559  0.876404  0.877335  0.876404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/svm_model.joblib']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึกโมเดล SVM 'poly' 'linear' 'rbf'\n",
    "svm_classifier = SVC(C=0.1, gamma=1, kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_lda_per_class = precision_score(y_test, y_pred_svm, average=None)\n",
    "recall_lda_per_class = recall_score(y_test, y_pred_svm, average=None)\n",
    "f1_lda_per_class = f1_score(y_test, y_pred_svm, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lda_per_class = []\n",
    "for class_label in range(len(precision_lda_per_class)):\n",
    "    correct_predictions = ((y_pred_svm == class_label) & (y_test == class_label)).sum()\n",
    "    # print(y_test)\n",
    "    total_predictions = (y_pred_svm == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lda_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lda = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lda = precision_score(y_test, y_pred_svm, average='weighted')\n",
    "avg_recall_lda = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "avg_f1_lda = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lda_per_class)),\n",
    "    'Precision': precision_lda_per_class,\n",
    "    'Recall': recall_lda_per_class,\n",
    "    'F1-score': f1_lda_per_class,\n",
    "    'Accuracy': accuracy_lda_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_df.loc['average'] = [None, avg_precision_lda, avg_recall_lda, avg_f1_lda, avg_accuracy_lda]\n",
    "\n",
    "print(results_df)\n",
    "dump(svm_classifier, 'model/svm_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # แบ่งข้อมูลเป็น train set และ test set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # กำหนดช่วงของ hyperparameters ที่ต้องการทดสอบ\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10, 100],  # regularization parameter\n",
    "#     'gamma': [1, 0.1, 0.01, 0.001],  # kernel coefficient\n",
    "#     'kernel': ['rbf', 'linear', 'poly']  # kernel function\n",
    "# }\n",
    "\n",
    "# # สร้าง GridSearchCV object\n",
    "# grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# # ฝึกโมเดล\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# # แสดง hyperparameters ที่ดีที่สุด\n",
    "# print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# # ทำนายบน test set\n",
    "# y_pred_svm = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# # ประเมินประสิทธิภาพของโมเดล SVM ที่ปรับ hyperparameters แล้ว\n",
    "# accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "# print(\"SVM Accuracy:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   1.000000  0.964286  0.981818  1.000000\n",
      "1          1.0   0.971429  0.971429  0.971429  0.971429\n",
      "2          2.0   0.962963  1.000000  0.981132  0.962963\n",
      "average    NaN   0.977944  0.977528  0.977532  0.977528\n",
      "SVM Confusion Matrix:\n",
      "[[54  2  0]\n",
      " [ 0 68  2]\n",
      " [ 0  0 52]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/lda_model.joblib']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# สร้างและฝึกโมเดล LDA\n",
    "lda_classifier = LinearDiscriminantAnalysis()\n",
    "lda_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_lda = lda_classifier.predict(X_test)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_lda_per_class = precision_score(y_test, y_pred_lda, average=None)\n",
    "recall_lda_per_class = recall_score(y_test, y_pred_lda, average=None)\n",
    "f1_lda_per_class = f1_score(y_test, y_pred_lda, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lda_per_class = []\n",
    "for class_label in range(len(precision_lda_per_class)):\n",
    "    correct_predictions = ((y_pred_lda == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_lda == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lda_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lda = accuracy_score(y_test, y_pred_lda)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lda = precision_score(y_test, y_pred_lda, average='weighted')\n",
    "avg_recall_lda = recall_score(y_test, y_pred_lda, average='weighted')\n",
    "avg_f1_lda = f1_score(y_test, y_pred_lda, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lda_per_class)),\n",
    "    'Precision': precision_lda_per_class,\n",
    "    'Recall': recall_lda_per_class,\n",
    "    'F1-score': f1_lda_per_class,\n",
    "    'Accuracy': accuracy_lda_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_df.loc['average'] = [None, avg_precision_lda, avg_recall_lda, avg_f1_lda, avg_accuracy_lda]\n",
    "\n",
    "print(results_df)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_lda)\n",
    "print(\"SVM Confusion Matrix:\")\n",
    "print(conf_matrix_svm)\n",
    "dump(lda_classifier, 'model/lda_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.784314  0.714286  0.747664  0.784314\n",
      "1          1.0   0.777778  0.800000  0.788732  0.777778\n",
      "2          2.0   0.927273  0.980769  0.953271  0.927273\n",
      "average    NaN   0.823507  0.825843  0.823879  0.825843\n",
      "KNN Confusion Matrix:\n",
      "[[40 16  0]\n",
      " [10 56  4]\n",
      " [ 1  0 51]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model/knn_model.joblib']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# สร้างและฝึกโมเดล KNN\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_knn_per_class = precision_score(y_test, y_pred_knn, average=None)\n",
    "recall_knn_per_class = recall_score(y_test, y_pred_knn, average=None)\n",
    "f1_knn_per_class = f1_score(y_test, y_pred_knn, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_knn_per_class = []\n",
    "for class_label in range(len(precision_knn_per_class)):\n",
    "    correct_predictions = ((y_pred_knn == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_knn == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_knn_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_knn = precision_score(y_test, y_pred_knn, average='weighted')\n",
    "avg_recall_knn = recall_score(y_test, y_pred_knn, average='weighted')\n",
    "avg_f1_knn = f1_score(y_test, y_pred_knn, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_knn_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_knn_per_class)),\n",
    "    'Precision': precision_knn_per_class,\n",
    "    'Recall': recall_knn_per_class,\n",
    "    'F1-score': f1_knn_per_class,\n",
    "    'Accuracy': accuracy_knn_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_knn_df.loc['average'] = [None, avg_precision_knn, avg_recall_knn, avg_f1_knn, avg_accuracy_knn]\n",
    "\n",
    "print(results_knn_df)\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
    "print(\"KNN Confusion Matrix:\")\n",
    "print(conf_matrix_knn)\n",
    "dump(knn_classifier, 'model/knn_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "23/23 [==============================] - 1s 2ms/step - loss: 2463286.2500 - accuracy: 0.6456\n",
      "Epoch 2/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 648.3765 - accuracy: 0.7398\n",
      "Epoch 3/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 254.6311 - accuracy: 0.7834\n",
      "Epoch 4/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 163.6100 - accuracy: 0.8115\n",
      "Epoch 5/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 97.5249 - accuracy: 0.8340\n",
      "Epoch 6/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 63.9412 - accuracy: 0.8608\n",
      "Epoch 7/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 55.8028 - accuracy: 0.8819\n",
      "Epoch 8/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 29.9993 - accuracy: 0.8889\n",
      "Epoch 9/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.6396 - accuracy: 0.9128\n",
      "Epoch 10/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 78.4351 - accuracy: 0.8579\n",
      "Epoch 11/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 82.3489 - accuracy: 0.8847\n",
      "Epoch 12/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 34.7557 - accuracy: 0.9030\n",
      "Epoch 13/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 16.7254 - accuracy: 0.9198\n",
      "Epoch 14/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 28.3929 - accuracy: 0.9198\n",
      "Epoch 15/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 24.2416 - accuracy: 0.9086\n",
      "Epoch 16/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 30.0513 - accuracy: 0.9142\n",
      "Epoch 17/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 80.7840 - accuracy: 0.8889\n",
      "Epoch 18/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 58.8551 - accuracy: 0.8762\n",
      "Epoch 19/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 83.1574 - accuracy: 0.8790\n",
      "Epoch 20/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 26.2074 - accuracy: 0.9297\n",
      "Epoch 21/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 16.6083 - accuracy: 0.9423\n",
      "Epoch 22/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.8584 - accuracy: 0.9634\n",
      "Epoch 23/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4912 - accuracy: 0.9887\n",
      "Epoch 24/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 9.6715 - accuracy: 0.9634\n",
      "Epoch 25/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 18.4452 - accuracy: 0.9367\n",
      "Epoch 26/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 10.6123 - accuracy: 0.9522\n",
      "Epoch 27/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.8439 - accuracy: 0.9859\n",
      "Epoch 28/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.7772 - accuracy: 0.9733\n",
      "Epoch 29/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6637 - accuracy: 0.9845\n",
      "Epoch 30/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 10.6311 - accuracy: 0.9564\n",
      "Epoch 31/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5.5935 - accuracy: 0.9789\n",
      "Epoch 32/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 19.2752 - accuracy: 0.9508\n",
      "Epoch 33/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 9.0426 - accuracy: 0.9550\n",
      "Epoch 34/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.6163 - accuracy: 0.9873\n",
      "Epoch 35/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.9902\n",
      "Epoch 36/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 5.7141 - accuracy: 0.9691\n",
      "Epoch 37/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.4737 - accuracy: 0.9845\n",
      "Epoch 38/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.4048 - accuracy: 0.9873\n",
      "Epoch 39/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 1.5035 - accuracy: 0.9916\n",
      "Epoch 40/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.3504 - accuracy: 0.9845\n",
      "Epoch 41/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.0216 - accuracy: 0.9705\n",
      "Epoch 42/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 4.0079 - accuracy: 0.9803\n",
      "Epoch 43/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.5247 - accuracy: 0.9817\n",
      "Epoch 44/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 9.4902 - accuracy: 0.9677\n",
      "Epoch 45/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 3.6766 - accuracy: 0.9803\n",
      "Epoch 46/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 11.3303 - accuracy: 0.9550\n",
      "Epoch 47/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8.4655 - accuracy: 0.9662\n",
      "Epoch 48/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 8.3485 - accuracy: 0.9662\n",
      "Epoch 49/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 11.3705 - accuracy: 0.9466\n",
      "Epoch 50/50\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 2.7698 - accuracy: 0.9831\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.904762  0.678571  0.775510  0.904762\n",
      "1          1.0   0.758621  0.942857  0.840764  0.758621\n",
      "2          2.0   0.979592  0.923077  0.950495  0.979592\n",
      "average    NaN   0.869151  0.853933  0.852291  0.853933\n",
      "ANN Confusion Matrix:\n",
      "[[38 18  0]\n",
      " [ 3 66  1]\n",
      " [ 1  3 48]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# แปลง y_train และ y_test ให้เป็นแบบ one-hot encoding\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# สร้างโมเดล ANN แบบ Feed-Forward\n",
    "ann_model = Sequential()\n",
    "ann_model.add(Dense(128, input_dim=X_train.shape[1], activation='relu'))\n",
    "ann_model.add(Dense(64, activation='relu'))\n",
    "ann_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "ann_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# ฝึกโมเดล\n",
    "ann_model.fit(X_train, y_train_one_hot, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_ann = np.argmax(ann_model.predict(X_test), axis=1)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_ann_per_class = precision_score(y_test, y_pred_ann, average=None)\n",
    "recall_ann_per_class = recall_score(y_test, y_pred_ann, average=None)\n",
    "f1_ann_per_class = f1_score(y_test, y_pred_ann, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_ann_per_class = []\n",
    "for class_label in range(len(precision_ann_per_class)):\n",
    "    correct_predictions = ((y_pred_ann == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_ann == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_ann_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_ann = accuracy_score(y_test, y_pred_ann)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_ann = precision_score(y_test, y_pred_ann, average='weighted')\n",
    "avg_recall_ann = recall_score(y_test, y_pred_ann, average='weighted')\n",
    "avg_f1_ann = f1_score(y_test, y_pred_ann, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_ann_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_ann_per_class)),\n",
    "    'Precision': precision_ann_per_class,\n",
    "    'Recall': recall_ann_per_class,\n",
    "    'F1-score': f1_ann_per_class,\n",
    "    'Accuracy': accuracy_ann_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_ann_df.loc['average'] = [None, avg_precision_ann, avg_recall_ann, avg_f1_ann, avg_accuracy_ann]\n",
    "\n",
    "print(results_ann_df)\n",
    "conf_matrix_ann = confusion_matrix(y_test, y_pred_ann)\n",
    "print(\"ANN Confusion Matrix:\")\n",
    "print(conf_matrix_ann)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/100\n",
      "23/23 [==============================] - 2s 21ms/step - loss: 0.5702 - accuracy: 0.8509\n",
      "Epoch 2/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3487 - accuracy: 0.9437\n",
      "Epoch 3/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1165 - accuracy: 0.9705\n",
      "Epoch 4/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1109 - accuracy: 0.9747\n",
      "Epoch 5/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1079 - accuracy: 0.9733\n",
      "Epoch 6/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.3157 - accuracy: 0.9606\n",
      "Epoch 7/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.1991 - accuracy: 0.9677\n",
      "Epoch 8/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0814 - accuracy: 0.9747\n",
      "Epoch 9/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0652 - accuracy: 0.9887\n",
      "Epoch 10/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0567 - accuracy: 0.9831\n",
      "Epoch 11/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0537 - accuracy: 0.9887\n",
      "Epoch 12/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0458 - accuracy: 0.9887\n",
      "Epoch 13/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0518 - accuracy: 0.9887\n",
      "Epoch 14/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0610 - accuracy: 0.9859\n",
      "Epoch 15/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0523 - accuracy: 0.9873\n",
      "Epoch 16/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0409 - accuracy: 0.9916\n",
      "Epoch 17/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0429 - accuracy: 0.9887\n",
      "Epoch 18/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0489 - accuracy: 0.9873\n",
      "Epoch 19/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0427 - accuracy: 0.9873\n",
      "Epoch 20/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0279 - accuracy: 0.9916\n",
      "Epoch 21/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0414 - accuracy: 0.9859\n",
      "Epoch 22/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0413 - accuracy: 0.9887\n",
      "Epoch 23/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0428 - accuracy: 0.9845\n",
      "Epoch 24/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0394 - accuracy: 0.9902\n",
      "Epoch 25/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0304 - accuracy: 0.9887\n",
      "Epoch 26/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0341 - accuracy: 0.9944\n",
      "Epoch 27/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0173 - accuracy: 0.9958\n",
      "Epoch 28/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0121 - accuracy: 0.9972\n",
      "Epoch 29/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0116 - accuracy: 0.9958\n",
      "Epoch 30/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0107 - accuracy: 0.9972\n",
      "Epoch 31/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0118 - accuracy: 0.9944\n",
      "Epoch 32/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0078 - accuracy: 0.9986\n",
      "Epoch 33/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0098 - accuracy: 0.9972\n",
      "Epoch 34/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0053 - accuracy: 0.9986\n",
      "Epoch 35/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0079 - accuracy: 0.9972\n",
      "Epoch 36/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 0.9986\n",
      "Epoch 37/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0066 - accuracy: 0.9986\n",
      "Epoch 38/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0072 - accuracy: 0.9972\n",
      "Epoch 39/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 42/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0071 - accuracy: 0.9986\n",
      "Epoch 43/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0077 - accuracy: 0.9972\n",
      "Epoch 44/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0105 - accuracy: 0.9944\n",
      "Epoch 45/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0097 - accuracy: 0.9972\n",
      "Epoch 47/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0039 - accuracy: 0.9986\n",
      "Epoch 48/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0048 - accuracy: 0.9972\n",
      "Epoch 51/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "23/23 [==============================] - 0s 19ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0035 - accuracy: 0.9986\n",
      "Epoch 56/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 58/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "23/23 [==============================] - 0s 22ms/step - loss: 0.0018 - accuracy: 0.9986\n",
      "Epoch 61/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 4.4715e-04 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.8356e-04 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0022 - accuracy: 0.9986\n",
      "Epoch 66/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 9.3665e-04 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 6.0466e-04 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 3.3215e-04 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0031 - accuracy: 0.9986\n",
      "Epoch 72/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 0.9986\n",
      "Epoch 76/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 7.8208e-04 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.8866e-04 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 4.0154e-04 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 2.5792e-04 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0033 - accuracy: 0.9986\n",
      "Epoch 83/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 8.3210e-04 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 7.6872e-04 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 6.1876e-04 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0023 - accuracy: 0.9986\n",
      "Epoch 89/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.8423e-04 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "23/23 [==============================] - 0s 21ms/step - loss: 4.0444e-04 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "23/23 [==============================] - 1s 22ms/step - loss: 2.2609e-04 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 5.3758e-04 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.5783e-05 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 4.1084e-04 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 7.0443e-04 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 1.4700e-04 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 1.4221e-04 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "23/23 [==============================] - 0s 20ms/step - loss: 8.1369e-05 - accuracy: 1.0000\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.981818  0.964286  0.972973  0.981818\n",
      "1          1.0   0.985714  0.985714  0.985714  0.985714\n",
      "2          2.0   0.962264  0.980769  0.971429  0.962264\n",
      "average    NaN   0.977638  0.977528  0.977532  0.977528\n",
      "CNN Confusion Matrix:\n",
      "[[54  0  2]\n",
      " [ 1 69  0]\n",
      " [ 0  1 51]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, BatchNormalization, MaxPooling1D, Dense, ReLU, Softmax, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize ข้อมูล\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ปรับข้อมูลให้เป็นรูปแบบ 3D สำหรับ Conv1D\n",
    "X_train_reshaped = X_train.reshape(-1, 363, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 363, 1)\n",
    "\n",
    "# สร้างโมเดล CNN สำหรับข้อมูล 1D\n",
    "model = Sequential()\n",
    "\n",
    "# Convolution Layer\n",
    "model.add(Conv1D(filters=64, kernel_size=3, input_shape=(363, 1), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(ReLU())\n",
    "\n",
    "# เพิ่มอีก Convolution Layer\n",
    "model.add(Conv1D(filters=64, kernel_size=3, padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(ReLU())\n",
    "\n",
    "# Dense Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=256))\n",
    "model.add(ReLU())\n",
    "\n",
    "# Output Layer\n",
    "num_classes = len(np.unique(y_train))\n",
    "model.add(Dense(units=num_classes))\n",
    "model.add(Softmax())\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# แปลง y_train และ y_test ให้เป็นแบบ one-hot encoding\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# ฝึกโมเดล\n",
    "model.fit(X_train_reshaped, y_train_one_hot, epochs=100, batch_size=32, verbose=1)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_cnn = np.argmax(model.predict(X_test_reshaped), axis=1)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_cnn_per_class = precision_score(y_test, y_pred_cnn, average=None)\n",
    "recall_cnn_per_class = recall_score(y_test, y_pred_cnn, average=None)\n",
    "f1_cnn_per_class = f1_score(y_test, y_pred_cnn, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_cnn_per_class = []\n",
    "for class_label in range(len(precision_cnn_per_class)):\n",
    "    correct_predictions = ((y_pred_cnn == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_cnn == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_cnn_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_cnn = accuracy_score(y_test, y_pred_cnn)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_cnn = precision_score(y_test, y_pred_cnn, average='weighted')\n",
    "avg_recall_cnn = recall_score(y_test, y_pred_cnn, average='weighted')\n",
    "avg_f1_cnn = f1_score(y_test, y_pred_cnn, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_cnn_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_cnn_per_class)),\n",
    "    'Precision': precision_cnn_per_class,\n",
    "    'Recall': recall_cnn_per_class,\n",
    "    'F1-score': f1_cnn_per_class,\n",
    "    'Accuracy': accuracy_cnn_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_cnn_df.loc['average'] = [None, avg_precision_cnn, avg_recall_cnn, avg_f1_cnn, avg_accuracy_cnn]\n",
    "\n",
    "print(results_cnn_df)\n",
    "conf_matrix_cnn = confusion_matrix(y_test, y_pred_cnn)\n",
    "print(\"CNN Confusion Matrix:\")\n",
    "print(conf_matrix_cnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 8s 205ms/step - loss: 1.1069 - accuracy: 0.3586 - val_loss: 1.1019 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.1035 - accuracy: 0.3615 - val_loss: 1.0955 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.1005 - accuracy: 0.3615 - val_loss: 1.0880 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0982 - accuracy: 0.3629 - val_loss: 1.0864 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0986 - accuracy: 0.3615 - val_loss: 1.0857 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0991 - accuracy: 0.3615 - val_loss: 1.0871 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0975 - accuracy: 0.3516 - val_loss: 1.0864 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0985 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0994 - accuracy: 0.3530 - val_loss: 1.0859 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0968 - accuracy: 0.3615 - val_loss: 1.0855 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0969 - accuracy: 0.3615 - val_loss: 1.0847 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0963 - accuracy: 0.3615 - val_loss: 1.0866 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0963 - accuracy: 0.3615 - val_loss: 1.0862 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0959 - accuracy: 0.3615 - val_loss: 1.0855 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0954 - accuracy: 0.3615 - val_loss: 1.0851 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0958 - accuracy: 0.3615 - val_loss: 1.0851 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0949 - accuracy: 0.3615 - val_loss: 1.0847 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0950 - accuracy: 0.3615\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0950 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0942 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0945 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0944 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0944 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0941 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0940 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0943 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0937 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0934 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0938 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0934 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0929 - accuracy: 0.3615\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0929 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0929 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0931 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0844 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0929 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0928 - accuracy: 0.3615\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0929 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0924 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0926 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0924 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0926 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0930 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0925 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0925 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0843 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0930 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0925 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0929 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0929 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0928 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0927 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0925 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0926 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0930 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0930 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0926 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0918 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0908 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.1129 - accuracy: 0.3615 - val_loss: 1.0668 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0976 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 1.0923 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "23/23 [==============================] - 4s 164ms/step - loss: 1.0923 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0923 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0919 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0919 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0921 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0916 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0913 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0911 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0911 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0909 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0907 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 87/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 88/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 89/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 90/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 91/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0907 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 92/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 93/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 94/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0909 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 95/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 96/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 97/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0908 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 98/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 99/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 100/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0908 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 101/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 102/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 103/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0901 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 104/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 105/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 106/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 107/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 108/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 109/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0842 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 110/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 111/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 112/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 113/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 114/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 115/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0908 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 116/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 117/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0901 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 118/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0901 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 119/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 120/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 121/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 122/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 123/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 124/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 125/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 126/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0899 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 127/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 128/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 129/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 130/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 131/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 132/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0901 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 133/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 134/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 135/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 136/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 137/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 138/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 139/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0907 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 140/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 141/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 142/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 143/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 144/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0909 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 145/200\n",
      "23/23 [==============================] - 4s 157ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 146/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 147/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0907 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 148/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 149/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 150/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 151/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 152/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 153/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 154/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0901 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 155/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0899 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 156/200\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 157/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0841 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 158/200\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 159/200\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 160/200\n",
      "23/23 [==============================] - 4s 171ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 161/200\n",
      "23/23 [==============================] - 4s 163ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 162/200\n",
      "23/23 [==============================] - 4s 173ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 163/200\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 164/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 165/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 166/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 167/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 168/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 169/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0897 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 170/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 171/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 172/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 173/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 174/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 175/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0906 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 176/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 177/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 178/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 179/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 180/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0897 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 181/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 182/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0904 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 183/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 184/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 185/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 186/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0908 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 187/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 188/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 189/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 190/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0902 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 191/200\n",
      "23/23 [==============================] - 4s 159ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 192/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0903 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 193/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0901 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 194/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 195/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0898 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 196/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0900 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 197/200\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 1.0909 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 198/200\n",
      "23/23 [==============================] - 4s 162ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 199/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0899 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "Epoch 200/200\n",
      "23/23 [==============================] - 4s 161ms/step - loss: 1.0905 - accuracy: 0.3615 - val_loss: 1.0840 - val_accuracy: 0.3933 - lr: 1.0000e-05\n",
      "6/6 [==============================] - 1s 55ms/step\n",
      "         Class  Precision    Recall  F1-score  Accuracy\n",
      "0          0.0   0.000000  0.000000  0.000000  0.000000\n",
      "1          1.0   0.393258  1.000000  0.564516  0.393258\n",
      "2          2.0   0.000000  0.000000  0.000000  0.000000\n",
      "average    NaN   0.154652  0.393258  0.222001  0.393258\n",
      "LSTM Confusion Matrix:\n",
      "[[ 0 56  0]\n",
      " [ 0 70  0]\n",
      " [ 0 52  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Toey\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# แบ่งข้อมูลเป็น train set และ test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize ข้อมูล\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ปรับข้อมูลให้เป็นรูปแบบ 3D สำหรับ LSTM\n",
    "X_train_reshaped = X_train.reshape(-1, 363, 1)\n",
    "X_test_reshaped = X_test.reshape(-1, 363, 1)\n",
    "\n",
    "# สร้างโมเดล LSTM\n",
    "model = Sequential()\n",
    "\n",
    "# LSTM Layer 1\n",
    "model.add(LSTM(50, return_sequences=True, input_shape=(363, 1), kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# LSTM Layer 2\n",
    "model.add(LSTM(70, return_sequences=False, kernel_regularizer=l2(0.0001)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Dense(5, activation='relu'))\n",
    "\n",
    "# Output Layer with Softmax\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "# คอมไพล์โมเดล\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# แปลง y_train และ y_test ให้เป็นแบบ one-hot encoding\n",
    "y_train_one_hot = tf.keras.utils.to_categorical(y_train, num_classes=len(np.unique(y_train)))\n",
    "y_test_one_hot = tf.keras.utils.to_categorical(y_test, num_classes=len(np.unique(y_train)))\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=0.00001, verbose=1)\n",
    "\n",
    "# ฝึกโมเดล\n",
    "model.fit(X_train_reshaped, y_train_one_hot, epochs=200, batch_size=32, validation_data=(X_test_reshaped, y_test_one_hot), callbacks=[reduce_lr], verbose=1)\n",
    "\n",
    "# ทำนายบน test set\n",
    "y_pred_lstm = np.argmax(model.predict(X_test_reshaped), axis=1)\n",
    "\n",
    "# ประเมิน precision, recall, และ F1-score ของแต่ละคลาส\n",
    "precision_lstm_per_class = precision_score(y_test, y_pred_lstm, average=None)\n",
    "recall_lstm_per_class = recall_score(y_test, y_pred_lstm, average=None)\n",
    "f1_lstm_per_class = f1_score(y_test, y_pred_lstm, average=None)\n",
    "\n",
    "# คำนวณ accuracy ของแต่ละคลาส\n",
    "accuracy_lstm_per_class = []\n",
    "for class_label in range(len(precision_lstm_per_class)):\n",
    "    correct_predictions = ((y_pred_lstm == class_label) & (y_test == class_label)).sum()\n",
    "    total_predictions = (y_pred_lstm == class_label).sum()\n",
    "    accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0\n",
    "    accuracy_lstm_per_class.append(accuracy)\n",
    "\n",
    "# คำนวณค่าเฉลี่ยของ accuracy\n",
    "avg_accuracy_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "\n",
    "# เฉลี่ย precision, recall, และ F1-score ของแต่ละคลาส\n",
    "avg_precision_lstm = precision_score(y_test, y_pred_lstm, average='weighted')\n",
    "avg_recall_lstm = recall_score(y_test, y_pred_lstm, average='weighted')\n",
    "avg_f1_lstm = f1_score(y_test, y_pred_lstm, average='weighted')\n",
    "\n",
    "# สร้าง DataFrame จากผลลัพธ์\n",
    "results_lstm_df = pd.DataFrame({\n",
    "    'Class': range(len(precision_lstm_per_class)),\n",
    "    'Precision': precision_lstm_per_class,\n",
    "    'Recall': recall_lstm_per_class,\n",
    "    'F1-score': f1_lstm_per_class,\n",
    "    'Accuracy': accuracy_lstm_per_class\n",
    "})\n",
    "\n",
    "# เพิ่มค่าเฉลี่ยของ accuracy และ precision, recall, F1-score ลงในตาราง\n",
    "results_lstm_df.loc['average'] = [None, avg_precision_lstm, avg_recall_lstm, avg_f1_lstm, avg_accuracy_lstm]\n",
    "\n",
    "print(results_lstm_df)\n",
    "conf_matrix_lstm = confusion_matrix(y_test, y_pred_lstm)\n",
    "print(\"LSTM Confusion Matrix:\")\n",
    "print(conf_matrix_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "streams_test1, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/test/6hz_10')\n",
    "raw_test1 = streams_test1[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n",
    "streams_test2, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/test/20hz_11')\n",
    "raw_test2 = streams_test2[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n",
    "streams_test3, header = pyxdf.load_xdf('../../../data_ssvep/Toey/SSVEP_data/test/0hz_10')\n",
    "raw_test3 = streams_test3[0][\"time_series\"].T #From Steam variable this query is EEG data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(83, 363)\n",
      "(83,)\n"
     ]
    }
   ],
   "source": [
    "data_test1 = raw_test1[0:4,:]\n",
    "data_test1_oz = data_test1[0] - data_test1[1]\n",
    "data_test1_o1 = data_test1[2] - data_test1[1]\n",
    "data_test1_o2 = data_test1[3] - data_test1[1]\n",
    "data_test1_set_oz = create_overlapping_sets(data_test1_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data_test1_set_o1 = create_overlapping_sets(data_test1_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data_test1_set_o2 = create_overlapping_sets(data_test1_o2, set_size=1000, overlap_fraction=0.5)\n",
    "data_test1_fft_oz = []\n",
    "data_test1_fft_o2 = []\n",
    "data_test1_fft_o1 = []\n",
    "for i in range(len(data_test1_set_oz)):\n",
    "    f, Pxx = welch(data_test1_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data_test1_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test1_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data_test1_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test1_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data_test1_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "combined_test1 = np.hstack((data_test1_fft_oz, data_test1_fft_o1, data_test1_fft_o2))\n",
    "# labels_test1 = np.array([0]*len(data_test1_fft_oz))\n",
    "# print(combined_test1.shape)\n",
    "# print(labels_test1.shape)\n",
    "data_test2 = raw_test2[0:4,:]\n",
    "data_test2_oz = data_test2[0] - data_test2[1]\n",
    "data_test2_o1 = data_test2[2] - data_test2[1]\n",
    "data_test2_o2 = data_test2[3] - data_test2[1]\n",
    "data_test2_set_oz = create_overlapping_sets(data_test2_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data_test2_set_o1 = create_overlapping_sets(data_test2_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data_test2_set_o2 = create_overlapping_sets(data_test2_o2, set_size=1000, overlap_fraction=0.5)\n",
    "data_test2_fft_oz = []\n",
    "data_test2_fft_o2 = []\n",
    "data_test2_fft_o1 = []\n",
    "for i in range(len(data_test2_set_oz)):\n",
    "    f, Pxx = welch(data_test2_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data_test2_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test2_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data_test2_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test2_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data_test2_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "combined_test2 = np.hstack((data_test2_fft_oz, data_test2_fft_o1, data_test2_fft_o2))\n",
    "# labels_test2 = np.array([0]*len(data_test2_fft_oz))\n",
    "# print(combined_test2.shape)\n",
    "# print(labels_test2.shape)\n",
    "\n",
    "data_test3 = raw_test3[0:4,:]\n",
    "data_test3_oz = data_test3[0] - data_test3[1]\n",
    "data_test3_o1 = data_test3[2] - data_test3[1]\n",
    "data_test3_o2 = data_test3[3] - data_test3[1]\n",
    "data_test3_set_oz = create_overlapping_sets(data_test3_oz, set_size=1000, overlap_fraction=0.5)\n",
    "data_test3_set_o1 = create_overlapping_sets(data_test3_o1, set_size=1000, overlap_fraction=0.5)\n",
    "data_test3_set_o2 = create_overlapping_sets(data_test3_o2, set_size=1000, overlap_fraction=0.5)\n",
    "data_test3_fft_oz = []\n",
    "data_test3_fft_o2 = []\n",
    "data_test3_fft_o1 = []\n",
    "for i in range(len(data_test3_set_oz)):\n",
    "    f, Pxx = welch(data_test3_set_oz[i], fs=250, nperseg= 250*4)\n",
    "    data_test3_fft_oz.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test3_set_o1[i], fs=250, nperseg= 250*4)\n",
    "    data_test3_fft_o1.append(Pxx[0:121])\n",
    "\n",
    "    f, Pxx = welch(data_test3_set_o2[i], fs=250, nperseg= 250*4)\n",
    "    data_test3_fft_o2.append(Pxx[0:121])\n",
    "\n",
    "combined_test3 = np.hstack((data_test3_fft_oz, data_test3_fft_o1, data_test3_fft_o2))\n",
    "# labels_test3 = np.array([0]*len(data_test3_fft_oz))\n",
    "# print(combined_test3.shape)\n",
    "# print(labels_test3.shape)\n",
    "\n",
    "# รวมข้อมูลจากทุก class เข้าด้วยกัน\n",
    "combined_test = np.vstack((combined_test1, combined_test2, combined_test3))\n",
    "\n",
    "  # ควรได้ (จำนวน samples ทั้งหมด, จำนวน features)\n",
    "\n",
    "# สร้าง label สำหรับแต่ละ class\n",
    "labels_test = np.array([0]*len(data_test1_fft_oz) + [1]*len(data_test2_fft_oz) + [2]*len(data_test3_fft_oz))\n",
    "# ตรวจสอบว่าข้อมูลมีขนาดที่ถูกต้อง\n",
    "print(combined_test.shape)\n",
    "print(labels_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf_test = rf_classifier.predict(combined_test)\n",
    "y_pred_svm_test = svm_classifier.predict(combined_test)\n",
    "y_pred_lda_test = lda_classifier.predict(combined_test)\n",
    "y_pred_knn_test = knn_classifier.predict(combined_test)\n",
    "\n",
    "avg_accuracy_rf_test = accuracy_score(y_pred_rf_test, labels_test)\n",
    "avg_accuracy_svm_test = accuracy_score(y_pred_svm_test, labels_test)\n",
    "avg_accuracy_lda_test = accuracy_score(y_pred_lda_test, labels_test)\n",
    "avg_accuracy_knn_test = accuracy_score(y_pred_knn_test, labels_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Precision_RF  Recall_RF     F1_RF  Precision_SVM  Recall_SVM    F1_SVM  \\\n",
      "Class                                                                           \n",
      "0          1.000000   0.965517  0.982456       0.805556        1.00  0.892308   \n",
      "1          0.961538   1.000000  0.980392       1.000000        0.72  0.837209   \n",
      "2          1.000000   1.000000  1.000000       1.000000        1.00  1.000000   \n",
      "\n",
      "       Precision_LDA  Recall_LDA  F1_LDA  Precision_KNN  Recall_KNN    F1_KNN  \n",
      "Class                                                                          \n",
      "0                1.0         1.0     1.0       0.828571        1.00  0.906250  \n",
      "1                1.0         1.0     1.0       1.000000        0.76  0.863636  \n",
      "2                1.0         1.0     1.0       1.000000        1.00  1.000000  \n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      " [[28  1  0]\n",
      " [ 0 25  0]\n",
      " [ 0  0 29]]\n",
      "\n",
      "Confusion Matrix for SVM:\n",
      " [[29  0  0]\n",
      " [ 7 18  0]\n",
      " [ 0  0 29]]\n",
      "\n",
      "Confusion Matrix for LDA:\n",
      " [[29  0  0]\n",
      " [ 0 25  0]\n",
      " [ 0  0 29]]\n",
      "\n",
      "Confusion Matrix for KNN:\n",
      " [[29  0  0]\n",
      " [ 6 19  0]\n",
      " [ 0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Assuming y_pred_rf_test, y_pred_svm_test, y_pred_lda_test, y_pred_knn_test, and labels_test are already defined\n",
    "\n",
    "def compute_metrics(y_true, y_pred, classes):\n",
    "    precision = precision_score(y_true, y_pred, average=None, labels=classes)\n",
    "    recall = recall_score(y_true, y_pred, average=None, labels=classes)\n",
    "    f1 = f1_score(y_true, y_pred, average=None, labels=classes)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred, labels=classes)\n",
    "    return precision, recall, f1, conf_matrix\n",
    "\n",
    "classes = np.unique(labels_test)\n",
    "\n",
    "# Calculate metrics for each classifier\n",
    "precision_rf, recall_rf, f1_rf, conf_matrix_rf = compute_metrics(labels_test, y_pred_rf_test, classes)\n",
    "precision_svm, recall_svm, f1_svm, conf_matrix_svm = compute_metrics(labels_test, y_pred_svm_test, classes)\n",
    "precision_lda, recall_lda, f1_lda, conf_matrix_lda = compute_metrics(labels_test, y_pred_lda_test, classes)\n",
    "precision_knn, recall_knn, f1_knn, conf_matrix_knn = compute_metrics(labels_test, y_pred_knn_test, classes)\n",
    "\n",
    "# Create DataFrames to display the results\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Class': classes,\n",
    "    'Precision_RF': precision_rf,\n",
    "    'Recall_RF': recall_rf,\n",
    "    'F1_RF': f1_rf,\n",
    "    'Precision_SVM': precision_svm,\n",
    "    'Recall_SVM': recall_svm,\n",
    "    'F1_SVM': f1_svm,\n",
    "    'Precision_LDA': precision_lda,\n",
    "    'Recall_LDA': recall_lda,\n",
    "    'F1_LDA': f1_lda,\n",
    "    'Precision_KNN': precision_knn,\n",
    "    'Recall_KNN': recall_knn,\n",
    "    'F1_KNN': f1_knn\n",
    "})\n",
    "\n",
    "metrics_df.set_index('Class', inplace=True)\n",
    "\n",
    "# Display the confusion matrices separately\n",
    "confusion_matrices = {\n",
    "    'Random Forest': conf_matrix_rf,\n",
    "    'SVM': conf_matrix_svm,\n",
    "    'LDA': conf_matrix_lda,\n",
    "    'KNN': conf_matrix_knn\n",
    "}\n",
    "\n",
    "print(metrics_df)\n",
    "\n",
    "# Print confusion matrices\n",
    "for clf_name, conf_matrix in confusion_matrices.items():\n",
    "    print(f\"\\nConfusion Matrix for {clf_name}:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
